% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ui_scraper.R
\name{scrape_website_ui}
\alias{scrape_website_ui}
\title{Scrape Website UI Components for Professional Theme Generation}
\usage{
scrape_website_ui(
  url,
  output_dir = tempdir(),
  user_agent =
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
  timeout = 30,
  num_themes = 3,
  interactive_mode = TRUE,
  batch_size = 10,
  verbose = TRUE
)
}
\arguments{
\item{url}{Character string specifying the website URL to scrape (e.g., "https://www.uni-hildesheim.de/").
Must be a valid HTTP or HTTPS URL.}

\item{output_dir}{Character string specifying the directory to save scraped files.
Default is a temporary directory that will be cleaned up after the session.}

\item{user_agent}{Character string specifying the user agent for HTTP requests.
Default is a standard browser user agent for compatibility.}

\item{timeout}{Numeric specifying the request timeout in seconds. Default is 30.
Increase for slower connections or complex websites.}

\item{num_themes}{Integer specifying the number of theme variations to generate.
Default is 3 (light, dark, and minimal variations).}

\item{interactive_mode}{Logical indicating whether to prompt user for confirmation
when processing large batches. Default is \code{TRUE}.}

\item{batch_size}{Integer specifying the maximum number of assets to process
in each batch before asking for user confirmation. Default is 10.}

\item{verbose}{Logical indicating whether to display detailed progress messages
and logging. Default is \code{TRUE}.}
}
\value{
Named list containing comprehensive scraping results:
\describe{
  \item{\code{themes}}{List of theme configurations, each containing \code{primary_color}, 
    \code{background_color}, \code{font_family}, \code{logo_path}, and metadata}
  \item{\code{html_file}}{Path to the saved HTML file}
  \item{\code{css_files}}{Vector of paths to downloaded CSS files}
  \item{\code{js_files}}{Vector of paths to downloaded JavaScript files}
  \item{\code{image_files}}{Vector of paths to downloaded images}
  \item{\code{scraped_colors}}{Vector of all colors extracted from CSS files}
  \item{\code{scraped_fonts}}{Vector of all fonts extracted from CSS files}
  \item{\code{processing_log}}{Vector of processing messages and status updates}
  \item{\code{errors}}{Vector of error messages encountered during scraping}
  \item{\code{warnings}}{Vector of warning messages and potential issues}
  \item{\code{source}}{Character string indicating the source of the themes}
}
}
\description{
Scrapes a website to extract UI components (logo, colors, fonts) and generates multiple
professional theme configurations for use in TAM-based adaptive testing interfaces.
This function enables researchers to create cohesive, branded assessment experiences
that align with institutional aesthetics and research requirements.
}
\details{
This function provides comprehensive website scraping capabilities for theme generation:

\strong{Scraping Process:}
\enumerate{
  \item Downloads and parses the main HTML page
  \item Extracts and downloads linked CSS stylesheets
  \item Identifies and downloads JavaScript files
  \item Locates and downloads images (logos, backgrounds)
  \item Analyzes CSS for color schemes and typography
  \item Generates multiple theme variations
}

\strong{Theme Generation:}
\itemize{
  \item \strong{Light Theme}: Bright backgrounds with dark text for readability
  \item \strong{Dark Theme}: Dark backgrounds with light text for reduced eye strain
  \item \strong{Minimal Theme}: Clean, distraction-free design for focus
  \item \strong{Custom Variations}: Based on extracted brand colors and fonts
}

\strong{Quality Assurance:}
\itemize{
  \item Comprehensive error handling and fallback mechanisms
  \item Interactive batch processing for large websites
  \item Detailed logging and progress reporting
  \item Validation of extracted assets and color schemes
}

\strong{File Organization:}
\itemize{
  \item \code{html/}: Downloaded HTML files
  \item \code{css/}: Extracted CSS stylesheets
  \item \code{js/}: JavaScript files
  \item \code{images/}: Logo and background images
}

\strong{AI-Assisted Customization:} We strongly encourage using Large Language Models
(LLMs) like ChatGPT, Claude, or Copilot to fine-tune the scraped components for your
specific study needs. Since psychological studies have unique requirements, AI assistance
can help you adapt themes for specific populations, accessibility requirements, 
cross-cultural research, and institutional branding guidelines.

\strong{Legal Compliance:} Before scraping a website, check its \code{robots.txt} and
terms of use to ensure compliance with legal and ethical guidelines. Respect privacy
and intellectual property rights when reusing website content.
}
\examples{
\dontrun{
# Example 1: Basic Website Scraping
library(inrep)

# Scrape university website for institutional branding
result <- scrape_website_ui("https://www.uni-hildesheim.de/")

# Preview scraped themes
cat("=== Scraped Themes Preview ===\n")
for (i in seq_along(result$themes)) {
  theme <- result$themes[[i]]
  cat(sprintf("Theme \%d: \%s\n", i, theme$name))
  cat(sprintf("  Primary Color: \%s\n", theme$primary_color))
  cat(sprintf("  Background: \%s\n", theme$background_color))
  cat(sprintf("  Font Family: \%s\n", theme$font_family))
  cat(sprintf("  Logo: \%s\n", ifelse(is.null(theme$logo_path), "None", "Available")))
  cat("\n")
}

# Example 2: Corporate Assessment with Brand Consistency
# Scrape corporate website for brand alignment
corporate_result <- scrape_website_ui(
  url = "https://www.company-website.com/",
  num_themes = 2,  # Light and dark versions
  verbose = TRUE
)

# Create study configuration with corporate theme
corporate_config <- create_study_config(
  name = "Employee Engagement Survey",
  model = "GRM",
  max_items = 20,
  theme = corporate_result$themes[[1]]$name,
  language = "en"
)

# Launch corporate assessment
launch_study(
  config = corporate_config,
  item_bank = bfi_items,
  theme_options = corporate_result$themes
)

# Example 3: Clinical Research with Professional Themes
# Scrape medical institution website
clinical_result <- scrape_website_ui(
  url = "https://www.medical-center.edu/",
  num_themes = 3,
  interactive_mode = FALSE,  # Automated processing
  timeout = 45  # Longer timeout for complex sites
)

# Create clinical assessment configuration
clinical_config <- create_study_config(
  name = "Depression Screening Tool",
  model = "GRM",
  max_items = 15,
  min_SEM = 0.4,
  demographics = c("Age", "Gender", "Previous_Treatment"),
  theme = "Clinical"
)

# Customize clinical themes for patient comfort
clinical_themes <- lapply(clinical_result$themes, function(theme) {
  # Soften colors for clinical environment
  theme$primary_color <- "#4a90a4"  # Calming blue
  theme$background_color <- "#f8f9fa"  # Soft white
  theme$font_family <- "'Helvetica Neue', Arial, sans-serif"
  theme$name <- paste("Clinical", theme$name)
  return(theme)
})

# Launch clinical assessment
launch_study(
  config = clinical_config,
  item_bank = bfi_items,
  theme_options = clinical_themes
)

# Example 4: Educational Assessment with School Branding
# Scrape school website for educational context
school_result <- scrape_website_ui(
  url = "https://www.school-district.edu/",
  output_dir = "school_themes",
  num_themes = 4,
  batch_size = 5
)

# Create educational assessment
educational_config <- create_study_config(
  name = "Mathematics Assessment",
  model = "2PL",
  max_items = 30,
  demographics = c("Grade", "Teacher", "School"),
  theme = "Educational"
)

# Adapt themes for young learners
educational_themes <- lapply(school_result$themes, function(theme) {
  # Bright, engaging colors for students
  theme$primary_color <- "#28a745"  # Encouraging green
  theme$accent_color <- "#ffc107"   # Attention-grabbing yellow
  theme$font_family <- "'Comic Sans MS', cursive"  # Kid-friendly font
  theme$name <- paste("Student", theme$name)
  return(theme)
})

# Example 5: Multi-Site Research with Consistent Branding
# Scrape multiple institutional websites
institutions <- c(
  "https://www.university1.edu/",
  "https://www.university2.edu/",
  "https://www.research-center.org/"
)

multi_site_themes <- list()
for (i in seq_along(institutions)) {
  cat("Scraping institution", i, ":", institutions[i], "\n")
  
  site_result <- scrape_website_ui(
    url = institutions[i],
    num_themes = 2,
    interactive_mode = FALSE,
    verbose = FALSE
  )
  
  # Add site identifier to themes
  site_themes <- lapply(site_result$themes, function(theme) {
    theme$site_id <- i
    theme$site_url <- institutions[i]
    theme$name <- paste("Site", i, theme$name)
    return(theme)
  })
  
  multi_site_themes <- c(multi_site_themes, site_themes)
}

# Create multi-site study configuration
multi_site_config <- create_study_config(
  name = "Multi-Site Personality Study",
  model = "GRM",
  max_items = 25,
  demographics = c("Site", "Age", "Gender", "Education"),
  language = "en"
)

# Launch with all scraped themes
launch_study(
  config = multi_site_config,
  item_bank = bfi_items,
  theme_options = multi_site_themes
)

# Example 6: AI-Assisted Theme Customization
# Prepare themes for AI customization
ai_customization_prompt <- function(scraped_result, study_context) {
  cat("=== AI Customization Prompt ===\n")
  cat("Please help me customize these scraped themes for a", study_context, "study.\n")
  cat("The themes should be professional, accessible, and appropriate for the context.\n\n")
  cat("Scraped themes:\n")
  cat(jsonlite::toJSON(scraped_result$themes, pretty = TRUE))
  cat("\n\nPlease provide:\n")
  cat("1. Customized color schemes appropriate for", study_context, "\n")
  cat("2. Font recommendations for optimal readability\n")
  cat("3. Accessibility improvements\n")
  cat("4. Cultural considerations if applicable\n")
  cat("5. Mobile optimization suggestions\n")
}

# Generate AI prompt for clinical study
ai_customization_prompt(clinical_result, "clinical depression assessment")

# Example 7: Theme Validation and Testing
# Validate scraped themes for assessment use
validate_scraped_themes <- function(scraped_result) {
  cat("Validating scraped themes...\n")
  cat("============================\n")
  
  validation_results <- list()
  
  for (i in seq_along(scraped_result$themes)) {
    theme <- scraped_result$themes[[i]]
    cat("Theme", i, ":", theme$name, "\n")
    
    # Color validation
    color_valid <- grepl("^#[0-9A-Fa-f]{6}$", theme$primary_color)
    cat("  Color format:", if (color_valid) "[OK] Valid" else "X Invalid", "\n")
    
    # Font validation
    font_valid <- !is.null(theme$font_family) && nchar(theme$font_family) > 0
    cat("  Font family:", if (font_valid) "[OK] Present" else "X Missing", "\n")
    
    # Logo validation
    logo_present <- !is.null(theme$logo_path) && file.exists(theme$logo_path)
    cat("  Logo file:", if (logo_present) "[OK] Available" else "X Missing", "\n")
    
    # Overall validation
    overall_valid <- color_valid && font_valid
    validation_results[[i]] <- overall_valid
    cat("  Overall:", if (overall_valid) "[OK] Valid" else "X Issues found", "\n\n")
  }
  
  # Summary
  valid_themes <- sum(unlist(validation_results))
  total_themes <- length(validation_results)
  cat("Summary:", valid_themes, "of", total_themes, "themes are valid\n")
  
  return(validation_results)
}

# Validate all scraped themes
validation_results <- validate_scraped_themes(result)

# Example 8: Error Handling and Fallback
# Demonstrate robust error handling
safe_scrape_website <- function(url) {
  tryCatch({
    result <- scrape_website_ui(url)
    cat("Successfully scraped:", url, "\n")
    return(result)
  }, error = function(e) {
    cat("Error scraping", url, ":", e$message, "\n")
    cat("Using default themes instead\n")
    
    # Return default themes as fallback
    return(list(
      themes = list(
        list(
          name = "Default Light",
          primary_color = "#007bff",
          background_color = "#ffffff",
          font_family = "'Inter', sans-serif",
          logo_path = NULL
        )
      ),
      source = "default_fallback"
    ))
  })
}

# Test with potentially problematic URLs
test_urls <- c(
  "https://www.valid-website.com/",
  "https://www.invalid-url-that-does-not-exist.com/",
  "https://www.timeout-prone-site.com/"
)

for (url in test_urls) {
  result <- safe_scrape_website(url)
  cat("Result source:", result$source, "\n\n")
}
}

\dontrun{
# Multiple website scraping for comparison
sites <- c(
  "https://www.uni-hildesheim.de/",
  "https://www.example-university.edu/",
  "https://www.research-institute.org/"
)

all_themes <- list()
for (site in sites) {
  cat(sprintf("Scraping \%s...\n", site))
  result <- scrape_website_ui(site, num_themes = 3)
  all_themes <- c(all_themes, result$themes)
}

# Compare and select best themes
cat(sprintf("Total themes collected: \%d\n", length(all_themes)))

# Error handling demonstration
tryCatch({
  result <- scrape_website_ui("https://invalid-url.com/")
}, error = function(e) {
  cat("Scraping failed gracefully with fallback themes\n")
})
}

}
\references{
\itemize{
  \item World Wide Web Consortium (W3C). (2018). Web Content Accessibility Guidelines (WCAG) 2.1. 
    \url{https://www.w3.org/WAI/WCAG21/Understanding/}
  \item Mozilla Developer Network. (2023). CSS Color Module Level 3. 
    \url{https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Color}
}
}
\seealso{
\itemize{
  \item \code{\link{build_study_ui}} for using scraped themes in UI construction
  \item \code{\link{launch_study}} for complete assessment workflow with themes
  \item \code{\link{get_builtin_themes}} for alternative built-in themes
  \item \code{\link{create_study_config}} for configuration with theme options
}
}
\keyword{UI}
\keyword{accessibility}
\keyword{branding}
\keyword{scraping}
\keyword{themes}
\keyword{web-scraping}
