% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/launch_study.R
\name{launch_study}
\alias{launch_study}
\title{Launch Adaptive Study Interface}
\usage{
launch_study(
  config,
  item_bank,
  custom_css = NULL,
  theme_config = NULL,
  webdav_url = NULL,
  password = NULL,
  save_format = "rds",
  logger = function(msg, ...) print(msg),
  ...
)
}
\arguments{
\item{config}{A list containing study configuration parameters created by \code{\link{create_study_config}}.
Must include essential elements like \code{model}, \code{max_items}, \code{min_SEM}, etc.}

\item{item_bank}{Data frame containing item parameters compatible with TAM package requirements.
Column structure varies by IRT model (see \strong{Item Bank Requirements} section).}

\item{custom_css}{Character string containing CSS code for UI customization. 
When provided, overrides both built-in themes and \code{theme_config} settings.}

\item{theme_config}{Named list of theme parameters (e.g., from \code{\link{launch_theme_editor}}).
Contains CSS variable definitions like \code{primary_color}, \code{font_family}, etc.}

\item{webdav_url}{Character string specifying WebDAV URL for cloud-based result storage,
or \code{NULL} to disable cloud functionality. Requires valid WebDAV credentials.}

\item{password}{Character string for WebDAV authentication when \code{webdav_url} is specified.}

\item{save_format}{Character string specifying output format for assessment results.
Options: \code{"rds"} (default), \code{"csv"}, \code{"json"}, \code{"pdf"}.}

\item{logger}{Function for custom logging. Default uses internal \code{logr} implementation.
Should accept \code{message} and \code{level} parameters.}

\item{...}{Additional parameters passed to Shiny application configuration.}

\item{admin_dashboard_hook}{Optional function receiving real-time assessment updates.
Called with participant progress, ability estimates, and session metrics.}

\item{accessibility}{Logical indicating whether to enable accessibility features
including ARIA labels, keyboard navigation, and screen reader support.}
}
\value{
A Shiny application object that can be run with \code{shiny::runApp()}.
  The app provides a complete assessment interface with real-time adaptation.
}
\description{
Launches a Shiny-based adaptive or non-adaptive assessment interface that serves as
a comprehensive wrapper around TAM's psychometric capabilities. All IRT computations
(ability estimation, item selection, model fitting) are performed by the TAM package,
while this function provides the interactive interface, workflow management, and
integration layer for comprehensive research workflows.
}
\details{
\strong{Psychometric Foundation:} All statistical computations are performed by the
TAM package (Robitzsch et al., 2020). \code{inrep} serves as an integration framework
that orchestrates TAM's capabilities within an interactive research workflow:
\itemize{
  \item IRT model fitting: \code{\link[TAM]{tam.mml}}, \code{\link[TAM]{tam.mml.2pl}}, \code{\link[TAM]{tam.mml.3pl}}
  \item Ability estimation: \code{\link[TAM]{tam.wle}}, \code{\link[TAM]{tam.eap}}
  \item Item information: \code{\link[TAM]{IRT.informationCurves}}
  \item Model diagnostics: \code{\link[TAM]{tam.fit}}
}

\strong{Framework Architecture:} \code{inrep} provides the following integration capabilities:
\itemize{
  \item Interactive web interface powered by Shiny (Chang et al., 2021)
  \item Real-time data collection and session management
  \item Bidirectional interface between user interactions and TAM computations
  \item Workflow orchestration with comprehensive logging via \code{logr} package
  \item Result export in multiple formats with cloud storage integration
}

\strong{Assessment Features:} This function provides comprehensive computerized 
adaptive testing (CAT) capabilities including:
\itemize{
  \item Multilingual interface support (English, German, Spanish, French)
  \item Configurable demographic data collection with validation
  \item Adaptive and non-adaptive administration modes
  \item Support for multiple IRT models (1PL/Rasch, 2PL, 3PL, GRM)
  \item Advanced item selection algorithms (Maximum Information, Weighted, Random)
  \item Real-time ability estimation using TAM's EAP and WLE methods
  \item Comprehensive result reporting with theta estimates, standard errors, and diagnostics
  \item Session state management with save/restore capabilities for interrupted sessions
  \item Enterprise-grade logging and audit trails via \code{logr} package
  \item Responsive design with accessibility compliance (WCAG 2.1 guidelines)
}

\strong{Advanced Features:}
\itemize{
  \item \strong{Real-time monitoring:} Use \code{admin_dashboard_hook} to receive live updates
    on participant progress, ability distribution patterns, and session metrics
  \item \strong{Accessibility compliance:} Enable \code{accessibility = TRUE} for ARIA labels,
    keyboard navigation, screen reader support, and high contrast options
  \item \strong{Cloud integration:} Specify \code{webdav_url} for automatic result backup
    to institutional cloud storage systems with secure authentication
  \item \strong{Quality monitoring:} Built-in detection of response patterns, engagement metrics,
    and data quality indicators with automatic flagging of suspicious sessions
}
}
\section{Installation and Dependencies}{

\strong{Required Packages:} Ensure all dependencies are installed for full functionality:
\preformatted{
# Core psychometric engine
install.packages("TAM")

# Interface and visualization  
install.packages(c("shiny", "DT", "ggplot2", "plotly"))

# Data processing and utilities
install.packages(c("dplyr", "jsonlite", "logr"))

# Install inrep package
devtools::install_github("selvastics/inrep")
}

\strong{System Requirements:}
\itemize{
  \item R version 4.0.0 or higher for optimal TAM compatibility
  \item Minimum 4GB RAM for medium-scale assessments (>500 participants)
  \item Modern web browser with JavaScript enabled for Shiny interface
  \item Network connectivity for cloud storage features (optional)
}
}

\section{Performance Optimization}{

For large-scale deployments and high-performance requirements:

\strong{Computational Settings:}
\itemize{
  \item Enable \code{parallel_computation = TRUE} in config for faster TAM estimation
  \item Use \code{cache_enabled = TRUE} to cache item information calculations
  \item Specify optimal \code{theta_grid} density based on precision requirements
  \item Consider \code{auto_scaling = TRUE} for cloud-based deployments
}

\strong{Monitoring Tools:}
\itemize{
  \item Built-in profiling tools track estimation times and memory usage
  \item Real-time performance metrics available through admin dashboard
  \item Automatic detection of computational bottlenecks and warnings
  \item Session timeout management prevents resource exhaustion
}

\strong{Scalability Considerations:}
\itemize{
  \item Recommended concurrent user limits: 50-100 depending on server specifications
  \item Database storage recommended for studies with >1000 participants  
  \item Load balancing support for enterprise deployments
  \item Memory management optimizations for long-running sessions
}
}

\section{Validation and Quality Assurance}{

The framework includes comprehensive validation and quality control mechanisms:

\strong{Real-time Response Quality:}
\itemize{
  \item Rapid response detection based on item-specific timing thresholds
  \item Response pattern analysis for detecting careless responding
  \item Engagement metrics including time-on-task and interaction patterns
  \item Automatic flagging of suspicious response sequences
}

\strong{Psychometric Quality:}
\itemize{
  \item Model fit diagnostics through TAM's \code{\link[TAM]{tam.fit}} procedures
  \item Person fit statistics for identifying aberrant response patterns
  \item Item functioning analysis with exposure rate monitoring
  \item Ability estimate stability tracking across administered items
}

\strong{Data Integrity:}
\itemize{
  \item Comprehensive audit trails with timestamped action logging
  \item Session state validation and recovery mechanisms
  \item Automatic data backup and redundancy for critical assessments
  \item GDPR-compliant data handling with participant consent management
}

\strong{Research Standards Compliance:}
\itemize{
  \item Follows Standards for Educational and Psychological Testing (AERA, APA, NCME, 2014)
  \item Implements International Test Commission Guidelines for Computer-Based Testing
  \item Supports institutional IRB requirements with built-in consent frameworks
  \item Accessibility compliance with WCAG 2.1 AA standards when enabled
}
}

\section{Theme Customization}{

The interface supports extensive theming capabilities through multiple mechanisms:

\strong{Built-in Themes:} Six professionally designed themes are available:
\itemize{
  \item \code{"Light"}: Clean, minimalist design with high contrast
  \item \code{"Midnight"}: Dark theme optimized for low-light environments  
  \item \code{"Sunset"}: Warm color palette with orange and red accents
  \item \code{"Forest"}: Nature-inspired greens with earthy tones
  \item \code{"Ocean"}: Cool blues and teals for calming effect
  \item \code{"Berry"}: Purple and magenta palette for creative applications
}

\strong{Custom Themes:} Create custom themes through:
\itemize{
  \item \code{theme_config}: Named list with CSS variable definitions
  \item \code{custom_css}: Direct CSS injection for complete control
  \item \code{\link{launch_theme_editor}}: Interactive theme builder with real-time preview
}

\strong{CSS Variables:} Key customization options include:
\itemize{
  \item \code{--primary-color}: Main interface accent color
  \item \code{--background-color}: Page and component backgrounds
  \item \code{--text-color}: Primary text color for readability
  \item \code{--font-family}: Typography selection (web-safe fonts recommended)
  \item \code{--border-radius}: Corner rounding for modern appearance
  \item \code{--button-hover-color}: Interactive element feedback
}

CSS customization takes precedence in this order: \code{custom_css} > \code{theme_config} > built-in themes.
}

\section{Item Bank Requirements}{

The \code{item_bank} data frame must conform to TAM package specifications with 
columns varying by IRT model type:

\strong{Common Requirements (All Models):}
\itemize{
  \item \code{Question}: Character vector containing item text or content identifiers
  \item Items must be properly formatted for the target language and population
  \item No missing values in parameter columns required by the specified model
}

\strong{Model-Specific Requirements:}
\describe{
  \item{\strong{1PL/Rasch Model}}{
    \itemize{
      \item \code{b}: Difficulty parameters (logit scale, typically -3 to +3)
      \item \code{Answer}: Correct response codes for scoring
      \item \code{Option1, Option2, ...}: Response options for multiple choice items
    }
  }
  \item{\strong{2PL Model}}{
    \itemize{
      \item \code{a}: Discrimination parameters (positive values, typically 0.5 to 3.0)
      \item \code{b}: Difficulty parameters (logit scale)
      \item \code{Answer}: Correct response identifiers
      \item \code{Option1, Option2, ...}: Multiple choice response options
    }
  }
  \item{\strong{3PL Model}}{
    \itemize{
      \item \code{a}: Discrimination parameters (positive values)
      \item \code{b}: Difficulty parameters (logit scale)  
      \item \code{c}: Guessing parameters (0 to 1, typically 0.1 to 0.3)
      \item \code{Answer}: Correct response codes
      \item \code{Option1, Option2, ...}: Distractor options
    }
  }
  \item{\strong{GRM (Graded Response Model)}}{
    \itemize{
      \item \code{a}: Discrimination parameters for polytomous items
      \item \code{b1, b2, b3, ...}: Threshold parameters in ascending order
      \item \code{ResponseCategories}: Comma-separated response scale (e.g., "1,2,3,4,5")
      \item Optional: \code{CategoryLabels}: Descriptive labels for scale points
    }
  }
}

\strong{Parameter Validation:} The function automatically validates:
\itemize{
  \item Parameter ranges appropriate for TAM estimation procedures
  \item Threshold ordering for polytomous models (b1 < b2 < b3 < ...)
  \item Consistency between model specification and available parameters
  \item Data types and missing value patterns that could affect TAM computations
}
}

\section{Installation and Setup}{

To use all features, ensure required packages are installed:
\preformatted{
install.packages(c("TAM", "shiny", "DT", "ggplot2", "logr"))
devtools::install_github("selvastics/inrep")
}
}

\section{Performance Considerations}{

For large-scale deployments:
\itemize{
  \item Enable \code{parallel_computation = TRUE} in config for faster ability estimation
  \item Use \code{cache_enabled = TRUE} to cache item information calculations  
  \item Consider \code{auto_scaling = TRUE} for cloud deployments
  \item Monitor performance with built-in profiling tools
}
}

\section{Validation and Quality}{

The framework includes comprehensive validation:
\itemize{
  \item Real-time response quality monitoring
  \item Automatic outlier detection
  \item Model fit diagnostics through TAM
  \item Engagement and completion tracking
  \item Comprehensive audit trails
}
inrep::launch_study(config, item_bank, accessibility = TRUE)
\dontrun{
# Example 1: Adaptive 2PL Model with Midnight Theme
config_2pl <- base::list(
  name = "Mathematics Proficiency",
  model = "2PL",
  max_items = 20,
  min_items = 5,
  min_SEM = 0.3,
  theta_prior = base::c(0, 1),
  adaptive = TRUE,
  theme = "Midnight",
  language = "en",
  demographics = base::c("Age", "Gender"),
  input_types = base::list(Age = "numeric", Gender = "select"),
  response_ui_type = "radio",
  progress_style = "circle",
  session_save = TRUE,
  max_session_duration = 30,
  recommendation_fun = function(theta, demo) {
    if (theta > 0) base::c("Consider advanced coursework", "Practice complex problems")
    else base::c("Review basic concepts", "Seek tutoring support")
  },
  response_validation_fun = function(resp) !base::is.null(resp) && base::length(resp) > 0,
  scoring_fun = function(resp, ans) base::as.numeric(resp == ans)
)
item_bank_2pl <- base::data.frame(
  Question = base::c("What is 2 + 2?", "What is 5 * 3?"),
  a = base::c(1.2, 1.0),
  b = base::c(0.5, -0.5),
  Option1 = base::c("2", "10"),
  Option2 = base::c("3", "12"),
  Option3 = base::c("4", "15"),
  Option4 = base::c("5", "18"),
  Answer = base::c("4", "15")
)
inrep::launch_study(config_2pl, item_bank_2pl)

# Example 2: Non-Adaptive GRM Model with Custom Theme
config_grm <- base::list(
  name = "Survey of Attitudes",
  model = "GRM",
  max_items = 10,
  adaptive = FALSE,
  theme = "Light",
  language = "de",
  demographics = base::c("Age"),
  input_types = base::list(Age = "numeric"),
  response_ui_type = "slider",
  progress_style = "circle",
  session_save = FALSE,
  max_session_duration = 15,
  recommendation_fun = function(score, demo) {
    if (base::mean(score) > 3) base::c("Positive attitude detected", "Continue engagement")
    else base::c("Consider motivational support", "Review responses")
  },
  response_validation_fun = function(resp) base::is.numeric(resp) && resp >= 1 && resp <= 5,
  scoring_fun = function(resp, ans) base::as.numeric(resp)
)
item_bank_grm <- base::data.frame(
  Question = base::c("I enjoy learning.", "I feel confident."),
  a = base::c(1.0, 1.1),
  b1 = base::c(-1.0, -0.8),
  b2 = base::c(-0.5, -0.3),
  b3 = base::c(0.0, 0.2),
  b4 = base::c(0.5, 0.7),
  ResponseCategories = base::c("1,2,3,4,5", "1,2,3,4,5")
)
custom_theme <- base::list(
  primary_color = "#007bff",
  background_color = "#e9ecef",
  font_family = "'Arial', sans-serif",
  font_size_base = "1.1rem",
  border_radius = "10px"
)
inrep::launch_study(config_grm, item_bank_grm, theme_config = custom_theme)

# Example 3: Adaptive 3PL Model with Custom CSS
config_3pl <- base::list(
  name = "Reading Comprehension",
  model = "3PL",
  max_items = 15,
  min_items = 5,
  min_SEM = 0.4,
  theta_prior = base::c(0, 1.5),
  adaptive = TRUE,
  theme = "Sunset",
  language = "en",
  demographics = base::c("Gender"),
  input_types = base::list(Gender = "select"),
  response_ui_type = "dropdown",
  progress_style = "circle",
  session_save = TRUE,
  max_session_duration = 20,
  recommendation_fun = function(theta, demo) {
    if (theta > 1) base::c("Advanced reading recommended", "Explore complex texts")
    else base::c("Practice basic comprehension", "Review vocabulary")
  },
  response_validation_fun = function(resp) !base::is.null(resp) && base::length(resp) > 0,
  scoring_fun = function(resp, ans) base::as.numeric(resp == ans)
)
item_bank_3pl <- base::data.frame(
  Question = base::c("What is the main idea?", "Who is the protagonist?"),
  a = base::c(1.3, 1.1),
  b = base::c(0.2, -0.2),
  c = base::c(0.2, 0.15),
  Option1 = base::c("Theme", "John"),
  Option2 = base::c("Plot", "Jane"),
  Option3 = base::c("Setting", "Jack"),
  Option4 = base::c("Character", "Jill"),
  Answer = base::c("Theme", "Jane")
)
custom_css <- "
  :root {
    --primary-color: #ff4500;
    --background-color: #fff8dc;
    --text-color: #333333;
    --font-family: 'Helvetica', sans-serif;
    --border-radius: 12px;
  }
  .btn-klee { background: var(--primary-color); }
  .assessment-card { border: 2px solid var(--primary-color); }
"
inrep::launch_study(config_3pl, item_bank_3pl, custom_css = custom_css)

# Example 4: Simple 1PL Model with Default Settings
config_1pl <- base::list(
  name = "Basic Arithmetic",
  model = "1PL",
  max_items = 5,
  adaptive = TRUE,
  theme = "Light",
  language = "en",
  demographics = NULL,
  response_ui_type = "radio",
  progress_style = "circle",
  session_save = FALSE,
  max_session_duration = 10,
  recommendation_fun = function(theta, demo) base::c("Practice more problems"),
  response_validation_fun = function(resp) !base::is.null(resp) && base::length(resp) > 0,
  scoring_fun = function(resp, ans) base::as.numeric(resp == ans)
)
item_bank_1pl <- base::data.frame(
  Question = base::c("1 + 1 =", "2 + 3 ="),
  b = base::c(0.0, 0.5),
  Option1 = base::c("1", "4"),
  Option2 = base::c("2", "5"),
  Option3 = base::c("3", "6"),
  Option4 = base::c("4", "7"),
  Answer = base::c("2", "5")
)
inrep::launch_study(config_1pl, item_bank_1pl)

# Example 5: Simple 1PL Model with Cloud Storage
config <- inrep::create_study_config(model = "GRM", max_items = 10, session_save = TRUE)
utils::data(bfi_items)
inrep::launch_study(config, bfi_items, webdav_url = "https://sync.academiccloud.de/index.php/s/Y51QPXzJVLWSAcb/", password = "inreptest")
}
}

\examples{
\dontrun{
# Example 1: Basic Personality Assessment with GRM
library(inrep)
data(bfi_items)

# Create basic configuration
basic_config <- create_study_config(
  name = "Big Five Personality Assessment",
  model = "GRM",
  max_items = 15,
  min_SEM = 0.3,
  demographics = c("Age", "Gender", "Education"),
  theme = "Light",
  language = "en"
)

# Launch assessment with default settings
launch_study(basic_config, bfi_items)

# Example 2: Advanced Cognitive Assessment with 2PL Model
advanced_config <- create_study_config(
  name = "Cognitive Ability Assessment",
  model = "2PL", 
  estimation_method = "TAM",
  max_items = 20,
  min_items = 10,
  min_SEM = 0.25,
  criteria = "MI",  # Maximum Information selection
  theta_prior = c(0, 1),
  demographics = c("Age", "Gender", "Education", "Native_Language"),
  input_types = list(
    Age = "numeric",
    Gender = "select", 
    Education = "select",
    Native_Language = "text"
  ),
  theme = "Professional",
  session_save = TRUE,
  parallel_computation = TRUE,
  cache_enabled = TRUE,
  accessibility_enhanced = TRUE
)

# Launch with accessibility features and admin monitoring
launch_study(
  config = advanced_config,
  item_bank = cognitive_items,
  accessibility = TRUE,
  admin_dashboard_hook = function(session_data) {
    cat("Participant ID:", session_data$participant_id, "\n")
    cat("Progress:", session_data$progress, "\%\n")
    cat("Current theta:", round(session_data$theta, 3), "\n")
    cat("Standard error:", round(session_data$se, 3), "\n")
  }
)

# Example 3: Custom Theme with CSS Variables
custom_theme_config <- list(
  primary_color = "#2E86AB",
  secondary_color = "#A23B72", 
  background_color = "#F5F5F5",
  text_color = "#333333",
  font_family = "'Segoe UI', Tahoma, Geneva, Verdana, sans-serif",
  border_radius = "8px",
  button_hover_color = "#1E5A6B"
)

launch_study(
  config = basic_config,
  item_bank = bfi_items, 
  theme_config = custom_theme_config
)

# Example 4: Enterprise Clinical Assessment
clinical_config <- create_study_config(
  name = "Clinical Depression Screening",
  model = "GRM",
  max_items = 12,
  min_SEM = 0.35,
  demographics = c("Age", "Gender", "Previous_Treatment"),
  theme = "Clinical",
  language = "en",
  enterprise_security = TRUE,
  audit_logging = TRUE,
  quality_monitoring = TRUE,
  session_save = TRUE,
  max_session_duration = 30
)

# Launch with cloud storage and comprehensive logging
launch_study(
  config = clinical_config,
  item_bank = depression_items,
  save_format = "json",
  webdav_url = "https://secure-storage.hospital.edu/assessments/",
  password = "secure_password_123",
  logger = function(msg, level = "INFO") {
    timestamp <- format(Sys.time(), "\%Y-\%m-\%d \%H:\%M:\%S")
    cat(sprintf("[\%s] \%s: \%s\n", timestamp, level, msg))
  }
)

# Example 5: Research Study with Complete Customization
research_config <- create_study_config(
  name = "Psychometric Validation Study",
  model = "3PL",
  estimation_method = "TAM",
  min_items = 15,
  max_items = 30,
  min_SEM = 0.2,
  criteria = "WEIGHTED",
  theta_prior = c(0, 1.2),
  demographics = c("Age", "Gender", "Education", "Country", "Language"),
  response_ui_type = "radio",
  progress_style = "circle",
  theme = "Research",
  language = "en",
  session_save = TRUE,
  parallel_computation = TRUE,
  feedback_enabled = TRUE,
  recommendation_fun = function(theta, demographics, responses) {
    if (theta > 1.0) {
      return(c("Excellent performance", "Consider advanced materials"))
    } else if (theta > 0) {
      return(c("Good performance", "Continue current approach"))
    } else {
      return(c("Additional support recommended", "Review fundamentals"))
    }
  }
)

# Custom CSS for research branding
research_css <- "
  :root {
    --primary-color: #1f4e79;
    --secondary-color: #8cc8ff;
    --background-color: #ffffff;
    --text-color: #2c3e50;
    --font-family: 'Georgia', serif;
    --border-radius: 6px;
  }
  
  .assessment-header {
    background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
    color: white;
    padding: 20px;
    text-align: center;
  }
  
  .progress-container {
    margin: 20px 0;
    text-align: center;
  }
"

launch_study(
  config = research_config,
  item_bank = validation_items,
  custom_css = research_css,
  save_format = "rds",
  accessibility = TRUE
)
}

}
\references{
\itemize{
  \item Robitzsch, A., Kiefer, T., & Wu, M. (2020). \emph{TAM: Test Analysis Modules}. 
    R package version 3.5-19. \url{https://CRAN.R-project.org/package=TAM}
  \item Chang, W., Cheng, J., Allaire, J., Xie, Y., & McPherson, J. (2021). 
    \emph{shiny: Web Application Framework for R}. R package version 1.6.0. 
    \url{https://CRAN.R-project.org/package=shiny}
  \item American Educational Research Association, American Psychological Association, 
    & National Council on Measurement in Education. (2014). 
    \emph{Standards for educational and psychological testing}. 
    American Educational Research Association.
  \item van der Linden, W. J., & Glas, C. A. W. (Eds.). (2010). 
    \emph{Elements of adaptive testing}. Springer.
  \item Embretson, S. E., & Reise, S. P. (2000). 
    \emph{Item response theory for psychologists}. Lawrence Erlbaum Associates.
}
}
\seealso{
\itemize{
  \item \code{\link{create_study_config}} for configuration parameters
  \item \code{\link{launch_theme_editor}} for interactive theme creation
  \item \code{\link{validate_item_bank}} for item bank validation
  \item \code{\link{estimate_ability}} for ability estimation details
  \item \code{\link{select_next_item}} for item selection algorithms
}
}
