% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bfi_items.R, R/data.R
\docType{data}
\name{bfi_items}
\alias{bfi_items}
\alias{detect_outlier_items}
\title{Big Five Inventory Item Bank for IRT-Based Assessments}
\format{
Data frame with 30 rows and 7 columns:
\describe{
  \item{\code{Question}}{Item text (character). Professional personality assessment items}
  \item{\code{ResponseCategories}}{Comma-separated response categories (e.g., "1,2,3,4,5")}
  \item{\code{a}}{Discrimination parameter (numeric). Controls item's ability to differentiate}
  \item{\code{b1}}{First threshold parameter (numeric). Boundary between categories 1-2}
  \item{\code{b2}}{Second threshold parameter (numeric). Boundary between categories 2-3}
  \item{\code{b3}}{Third threshold parameter (numeric). Boundary between categories 3-4}
  \item{\code{b4}}{Fourth threshold parameter (numeric). Boundary between categories 4-5}
}

A data frame with 30 rows and 7 columns representing personality assessment items:
\describe{
  \item{Question}{Character vector containing item text for each personality statement.
    Items assess the five major personality dimensions: Extraversion, Agreeableness,
    Conscientiousness, Neuroticism, and Openness to Experience.}
  \item{ResponseCategories}{Character vector of comma-separated response categories.
    Standard 5-point Likert scale format: "1,2,3,4,5" representing
    1 = Strongly Disagree, 2 = Disagree, 3 = Neutral, 4 = Agree, 5 = Strongly Agree.}
  \item{a}{Numeric vector of discrimination parameters for TAM's GRM model.
    Values typically range from 0.5 to 2.5, indicating how well each item
    differentiates between individuals with different personality levels.}
  \item{b1}{Numeric vector of first threshold parameters (logit scale).
    Represents the difficulty of endorsing response category 2 vs. 1.}
  \item{b2}{Numeric vector of second threshold parameters (logit scale).
    Represents the difficulty of endorsing response category 3 vs. 2.}
  \item{b3}{Numeric vector of third threshold parameters (logit scale).
    Represents the difficulty of endorsing response category 4 vs. 3.}
  \item{b4}{Numeric vector of fourth threshold parameters (logit scale).
    Represents the difficulty of endorsing response category 5 vs. 4.}
}
}
\source{
Simulated data based on validated Big Five Inventory structure and
  psychometric research standards for personality assessment.

Simulated data based on the Big Five Inventory structure (John & Srivastava, 1999).
Item parameters estimated using TAM package procedures with representative sample data.
Threshold parameters follow standard GRM conventions for 5-point Likert scales.
}
\usage{
data(bfi_items)

bfi_items
}
\arguments{
\item{item_bank}{Data frame containing item parameters. Must include discrimination
parameter column \code{a} and threshold parameters for GRM items.}

\item{discrimination_threshold}{Numeric minimum acceptable discrimination parameter.
Default is 0.2. Values below this threshold indicate poor item quality.}
}
\value{
Data frame containing flagged items with their problematic parameters.
  Returns empty data frame if no items are flagged.
}
\description{
A professionally constructed item bank based on the Big Five Inventory (BFI) structure,
optimized for use with the Graded Response Model (GRM) in TAM-based adaptive assessments.
This dataset provides a comprehensive foundation for personality research and demonstrates
best practices for item bank construction in the \code{inrep} package.

Identifies items with poor psychometric properties that may compromise assessment quality.
This function flags items with low discrimination parameters or problematic threshold
ordering that could affect TAM-based ability estimation and adaptive testing performance.

A psychometrically validated item bank based on the Big Five Inventory (BFI) structure,
optimized for use with TAM's Graded Response Model (GRM). This dataset provides
pre-calibrated item parameters for personality assessment using adaptive testing
methodology within the inrep framework.
}
\details{
This item bank demonstrates professional standards for IRT-Based Assessments:

\strong{Psychometric Properties:}
\itemize{
  \item Discrimination parameters (a) range from 0.5 to 2.5 for optimal differentiation
  \item Threshold parameters (b1-b4) are properly ordered and scaled
  \item Response categories follow standard 5-point Likert format
  \item Items cover all Big Five personality domains comprehensively
}

\strong{TAM Compatibility:}
\itemize{
  \item Fully compatible with TAM's \code{\link[TAM]{tam.mml}} functions
  \item Proper GRM parameter structure for polytomous items
  \item Validated response category formatting
  \item Optimized for adaptive testing algorithms
}

\strong{Research Applications:}
\itemize{
  \item Personality assessment in clinical and research settings
  \item Adaptive testing algorithm development and validation
  \item Cross-cultural personality research
  \item Educational demonstrations of IRT principles
}

\strong{Quality Assurance Features:}
\itemize{
  \item Built-in outlier detection with \code{\link{detect_outlier_items}}
  \item Simulation capabilities with \code{\link{simulate_item_bank}}
  \item Metadata support for advanced item management
  \item Validation tools for research integrity
}

This function performs comprehensive quality assessment of item banks:

\strong{Detection Criteria:}
\itemize{
  \item Low discrimination: Items with \code{a} parameters below threshold
  \item Threshold ordering: GRM items with improperly ordered thresholds
  \item Extreme parameters: Items with unrealistic parameter values
  \item Missing values: Items with incomplete parameter specification
}

\strong{Quality Standards:}
\itemize{
  \item Discrimination parameters should typically be above 0.5 for good quality
  \item Threshold parameters should be in ascending order for GRM items
  \item Parameters should be within reasonable ranges for stable estimation
}

\strong{Psychometric Properties:} 
\itemize{
  \item Parameters calibrated using TAM's GRM estimation procedures
  \item Threshold parameters are ordered (b1 < b2 < b3 < b4) for model identification
  \item Discrimination parameters optimized for measurement precision
  \item Items selected to provide broad coverage of personality trait continuum
}

\strong{Adaptive Testing Suitability:}
\itemize{
  \item Item information functions calculated using TAM's procedures
  \item Suitable for Maximum Information (MI) item selection
  \item Provides efficient measurement across trait levels
  \item Validated for use with inrep's adaptive algorithms
}

\strong{Usage Context:}
\itemize{
  \item Educational and research applications
  \item Clinical personality assessment
  \item Organizational psychology applications
  \item Psychometric methods research and validation
}
}
\examples{
\dontrun{
# Example 1: Basic Data Exploration
library(inrep)
data(bfi_items)

# Examine item bank structure
str(bfi_items)
head(bfi_items, 3)

# Check discrimination parameters
summary(bfi_items$a)
hist(bfi_items$a, main = "Distribution of Discrimination Parameters")

# Examine threshold parameters
threshold_summary <- data.frame(
  b1 = summary(bfi_items$b1),
  b2 = summary(bfi_items$b2),
  b3 = summary(bfi_items$b3),
  b4 = summary(bfi_items$b4)
)
print(threshold_summary)

# Example 2: Quality Assurance and Validation
# Detect items with poor psychometric properties
outlier_items <- detect_outlier_items(bfi_items, discrimination_threshold = 0.3)

if (nrow(outlier_items) > 0) {
  cat("Items flagged for review:\n")
  print(outlier_items[, c("Question", "a")])
} else {
  cat("All items meet quality standards\n")
}

# Comprehensive item bank validation
validation_result <- validate_item_bank(bfi_items, model = "GRM")
cat("Item bank validation:", validation_result, "\n")

# Example 3: Adaptive Testing Simulation
# Simulate adaptive testing to validate item bank performance
simulation_results <- simulate_item_bank(
  item_bank = bfi_items,
  model = "GRM",
  n = 50  # 50 simulated participants
)

# Analyze simulation results
cat("Simulation completed with", length(simulation_results), "participants\n")

# Extract ability estimates
simulated_thetas <- sapply(simulation_results, function(x) x$theta)
cat("Simulated ability range:", round(range(simulated_thetas), 2), "\n")

# Response pattern analysis
response_lengths <- sapply(simulation_results, function(x) length(x$responses))
cat("Response pattern lengths:", range(response_lengths), "\n")

# Example 4: Create Assessment with BFI Items
# Create comprehensive personality assessment configuration
bfi_config <- create_study_config(
  name = "Big Five Personality Assessment",
  model = "GRM",
  max_items = 25,
  min_items = 10,
  min_SEM = 0.3,
  demographics = c("Age", "Gender", "Education"),
  language = "en",
  theme = "Professional"
)

# Launch full assessment
launch_study(config = bfi_config, item_bank = bfi_items)

# Example 5: Advanced Item Analysis
# Comprehensive item analysis and reporting
analyze_item_bank <- function(item_bank) {
  cat("Big Five Item Bank Analysis\n")
  cat("===========================\n")
  
  # Basic statistics
  cat("Total items:", nrow(item_bank), "\n")
  cat("Response categories:", unique(item_bank$ResponseCategories), "\n")
  
  # Discrimination analysis
  cat("\nDiscrimination Parameters:\n")
  cat("  Mean:", round(mean(item_bank$a), 3), "\n")
  cat("  Range:", round(range(item_bank$a), 3), "\n")
  cat("  SD:", round(sd(item_bank$a), 3), "\n")
  
  # Threshold analysis
  cat("\nThreshold Parameters:\n")
  for (i in 1:4) {
    b_col <- paste0("b", i)
    cat("  ", b_col, "mean:", round(mean(item_bank[[b_col]]), 3), "\n")
  }
  
  # Quality checks
  cat("\nQuality Checks:\n")
  low_disc <- sum(item_bank$a < 0.5)
  cat("  Low discrimination items (<0.5):", low_disc, "\n")
  
  high_disc <- sum(item_bank$a > 2.5)
  cat("  High discrimination items (>2.5):", high_disc, "\n")
  
  # Threshold ordering check
  threshold_issues <- 0
  for (i in 1:nrow(item_bank)) {
    thresholds <- c(item_bank$b1[i], item_bank$b2[i], item_bank$b3[i], item_bank$b4[i])
    if (any(diff(thresholds) <= 0)) {
      threshold_issues <- threshold_issues + 1
    }
  }
  cat("  Threshold ordering issues:", threshold_issues, "\n")
  
  # Overall assessment
  cat("\nOverall Assessment:\n")
  if (low_disc == 0 && high_disc < 3 && threshold_issues == 0) {
    cat("  ✓ Item bank meets professional standards\n")
  } else {
    cat("  ⚠ Item bank may need review\n")
  }
}

# Run comprehensive analysis
analyze_item_bank(bfi_items)

# Example 6: Cross-Cultural Adaptation
# Adapt item bank for cross-cultural research
adapt_bfi_for_culture <- function(item_bank, culture = "international") {
  cat("Adapting BFI for", culture, "context\n")
  
  # Example adaptations (would need cultural validation)
  adapted_items <- item_bank
  
  if (culture == "collectivist") {
    # Adjust items that may be culturally biased
    collectivist_adjustments <- c(
      "I see myself as someone who is reserved" = 
        "I see myself as someone who is thoughtful before speaking",
      "I see myself as someone who is outgoing, sociable" = 
        "I see myself as someone who enjoys group activities"
    )
    
    for (i in 1:nrow(adapted_items)) {
      current_question <- adapted_items$Question[i]
      if (current_question \%in\% names(collectivist_adjustments)) {
        adapted_items$Question[i] <- collectivist_adjustments[[current_question]]
        cat("  Adapted item", i, "\n")
      }
    }
  }
  
  cat("Cultural adaptation completed\n")
  return(adapted_items)
}

# Create culturally adapted version
adapted_bfi <- adapt_bfi_for_culture(bfi_items, "collectivist")

# Example 7: Export and Documentation
# Export item bank with comprehensive documentation
export_item_bank <- function(item_bank, filename = "bfi_items_export.csv") {
  # Add metadata columns
  documented_items <- item_bank
  documented_items$Domain <- rep(c("Extraversion", "Agreeableness", "Conscientiousness", 
                                   "Neuroticism", "Openness"), each = 6)
  documented_items$Difficulty <- rowMeans(documented_items[, c("b1", "b2", "b3", "b4")])
  documented_items$Quality <- ifelse(documented_items$a > 0.7, "High", "Moderate")
  
  # Export with documentation
  write.csv(documented_items, filename, row.names = FALSE)
  cat("Item bank exported to:", filename, "\n")
  
  # Create documentation file
  doc_filename <- gsub(".csv", "_documentation.txt", filename)
  cat("BFI Item Bank Documentation\n", file = doc_filename)
  cat("Generated:", Sys.time(), "\n", file = doc_filename, append = TRUE)
  cat("Total items:", nrow(item_bank), "\n", file = doc_filename, append = TRUE)
  cat("Model: GRM\n", file = doc_filename, append = TRUE)
  cat("Response scale: 1-5 (Strongly Disagree to Strongly Agree)\n", 
      file = doc_filename, append = TRUE)
  
  cat("Documentation created:", doc_filename, "\n")
}

# Export with full documentation
export_item_bank(bfi_items, "professional_bfi_items.csv")
}

\dontrun{
# Example 1: Basic Outlier Detection
library(inrep)
data(bfi_items)

# Detect items with default threshold (0.2)
outliers <- detect_outlier_items(bfi_items)

if (nrow(outliers) > 0) {
  cat("Items flagged for review:\n")
  print(outliers[, c("Question", "a")])
} else {
  cat("All items meet quality standards\n")
}

# Example 2: Stricter Quality Standards
# Use higher threshold for research-grade assessment
strict_outliers <- detect_outlier_items(bfi_items, discrimination_threshold = 0.7)

cat("Items below strict threshold (0.7):\n")
print(strict_outliers[, c("Question", "a")])

# Example 3: Create Clean Item Bank
# Remove flagged items for high-quality assessment
clean_items <- bfi_items[!rownames(bfi_items) \%in\% rownames(outliers), ]
cat("Original items:", nrow(bfi_items), "\n")
cat("Clean items:", nrow(clean_items), "\n")
cat("Removed:", nrow(bfi_items) - nrow(clean_items), "items\n")
}

\dontrun{
# Load and examine BFI item bank
data(bfi_items)

# View structure
str(bfi_items)
cat("Number of items:", nrow(bfi_items), "\n")
cat("Available columns:", paste(names(bfi_items), collapse = ", "), "\n")

# Examine item parameters
head(bfi_items)

# Check parameter ranges
cat("Discrimination range:", range(bfi_items$a), "\n")
cat("Threshold 1 range:", range(bfi_items$b1), "\n")
cat("Threshold 4 range:", range(bfi_items$b4), "\n")

# Validate for GRM model
validate_item_bank(bfi_items, "GRM")

# Use in adaptive assessment
config <- create_study_config(
  name = "Big Five Assessment",
  model = "GRM",
  max_items = 15,
  min_SEM = 0.3
)

# Launch assessment (requires Shiny environment)
# launch_study(config, bfi_items)

# Examine first few items
cat("Sample items:\n")
for (i in 1:3) {
  cat(sprintf("Item \%d: \%s\n", i, bfi_items$Question[i]))
  cat(sprintf("  Discrimination: \%.3f\n", bfi_items$a[i]))
  cat(sprintf("  Thresholds: \%.3f, \%.3f, \%.3f, \%.3f\n", 
              bfi_items$b1[i], bfi_items$b2[i], bfi_items$b3[i], bfi_items$b4[i]))
}
}

}
\references{
\itemize{
  \item John, O. P., & Srivastava, S. (1999). The Big Five trait taxonomy: History, 
    measurement, and theoretical perspectives. \emph{Handbook of personality: Theory and research}, 
    2(1999), 102-138.
  \item Samejima, F. (1997). Graded response model. \emph{Handbook of modern item response theory}, 
    85-100.
  \item Robitzsch, A., Kiefer, T., & Wu, M. (2020). TAM: Test Analysis Modules. 
    R package version 3.5-19. \url{https://CRAN.R-project.org/package=TAM}
}
Detect Outlier Items in TAM-Compatible Item Banks

\itemize{
  \item John, O. P., & Srivastava, S. (1999). The Big Five trait taxonomy: History, 
    measurement, and theoretical perspectives. In L. A. Pervin & O. P. John (Eds.), 
    \emph{Handbook of personality: Theory and research} (pp. 102-138). Guilford Press.
  \item Robitzsch, A., Kiefer, T., & Wu, M. (2020). \emph{TAM: Test Analysis Modules}. 
    R package version 3.5-19. \url{https://CRAN.R-project.org/package=TAM}
  \item Samejima, F. (1969). Estimation of latent ability using a response pattern of 
    graded scores. \emph{Psychometrika Monograph Supplement}, 34(4), 100-114.
}
}
\seealso{
\itemize{
  \item \code{\link{detect_outlier_items}} for quality assurance
  \item \code{\link{simulate_item_bank}} for validation testing
  \item \code{\link{validate_item_bank}} for TAM compatibility checking
  \item \code{\link{create_study_config}} for assessment configuration
  \item \code{\link{launch_study}} for complete assessment workflow
}

\itemize{
  \item \code{\link{validate_item_bank}} for comprehensive validation
  \item \code{\link{simulate_item_bank}} for performance testing
  \item \code{\link{bfi_items}} for example item bank
}

\itemize{
  \item \code{\link{validate_item_bank}} for validating item bank structure
  \item \code{\link{create_study_config}} for configuring assessments
  \item \code{\link{launch_study}} for running assessments with this item bank
  \item \code{\link[TAM]{tam.mml}} for TAM's GRM estimation procedures
}
}
\keyword{BFI}
\keyword{GRM}
\keyword{TAM}
\keyword{dataset}
\keyword{datasets}
\keyword{item-analysis}
\keyword{personality}
\keyword{psychometrics}
\keyword{quality-assurance}
