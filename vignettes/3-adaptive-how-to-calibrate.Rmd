---
title: "How to Calibrate Your Item Bank with inrep"
author: "inrep Development Team"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    theme: cerulean
    css: styles.css
vignette: >
  %\VignetteIndexEntry{How to Calibrate Your Item Bank with inrep}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
library(inrep)
```

In this vignette, we will learn how to calibrate your item bank to create more accurate adaptive assessments. We use the Big Five personality inventory from the psych package as our example.

## Installation
```{r eval=FALSE}

# Install development version from GitHub
devtools::install_github("selvastics/inrep")
```

## Let's start by exploring our data

First, let's load and examine the Big Five personality data from the psych package:

```{r load_data, eval=FALSE}
#install.packages("psych")
library(psych)
data(bfi)

# Examine the data structure
describe(bfi)

#          vars    n  mean    sd median trimmed   mad min max range  skew kurtosis   se
#A1           1 2784  2.41  1.41      2    2.23  1.48   1   6     5  0.83    -0.31 0.03
#A2           2 2773  4.80  1.17      5    4.98  1.48   1   6     5 -1.12     1.05 0.02
#A3           3 2774  4.60  1.30      5    4.79  1.48   1   6     5 -1.00     0.44 0.02
#A4           4 2781  4.70  1.48      5    4.93  1.48   1   6     5 -1.03     0.04 0.03
#A5           5 2784  4.56  1.26      5    4.71  1.48   1   6     5 -0.85     0.16 0.02
#C1           6 2779  4.50  1.24      5    4.64  1.48   1   6     5 -0.85     0.30 0.02
#C2           7 2776  4.37  1.32      5    4.50  1.48   1   6     5 -0.74    -0.14 0.03
#C3           8 2780  4.30  1.29      5    4.42  1.48   1   6     5 -0.69    -0.13 0.02
#C4           9 2774  2.55  1.38      2    2.41  1.48   1   6     5  0.60    -0.62 0.03
#C5          10 2784  3.30  1.63      3    3.25

items <- bfi[,1:25]

dim(items)
# [1] 2800   25

# We have 25 items and 2800 participants as basis for our item bank
```

## Fitting IRT Models with TAM

Now let's fit a Graded Response Model (GRM) to calibrate our items using the TAM package:

```{r fit_grm, eval=FALSE}
#install.packages("TAM")
library(TAM)

# Fit a GRM model to the items
mod <- tam.mml(items) # TAM will recognize our polytomous data type
summary(mod)
mod$item  # Here are the item parameters

# Note: This model assumes all BFI items measure one latent dimension
# In the BFI context, this doesn't make much sense - items measure 5 different dimensions
# We should fit multidimensional models (see Example 23 in tam.mml of the TAM package)
```

## Proper Multidimensional Calibration

Since the BFI measures 5 distinct personality dimensions, let's fit separate models for each dimension:

```{r multidimensional_calibration, eval=FALSE}
# Split items by Big Five dimension
items_A <- items[, grep("^A", colnames(items))]  # Agreeableness
items_C <- items[, grep("^C", colnames(items))]  # Conscientiousness
items_E <- items[, grep("^E", colnames(items))]  # Extraversion
items_N <- items[, grep("^N", colnames(items))]  # Neuroticism
items_O <- items[, grep("^O", colnames(items))]  # Openness

# Fit 5 separate GRM models (one per dimension)
mod_A <- TAM::tam.mml(resp = items_A, control = list(maxiter = 100))
mod_C <- TAM::tam.mml(resp = items_C, control = list(maxiter = 100))
mod_E <- TAM::tam.mml(resp = items_E, control = list(maxiter = 100))
mod_N <- TAM::tam.mml(resp = items_N, control = list(maxiter = 100))
mod_O <- TAM::tam.mml(resp = items_O, control = list(maxiter = 100))

# Extract item parameters for each dimension
params_A <- mod_A$item[, c("item", "N", "M", "xsi.item")]
params_C <- mod_C$item[, c("item", "N", "M", "xsi.item")]
params_E <- mod_E$item[, c("item", "N", "M", "xsi.item")]
params_N <- mod_N$item[, c("item", "N", "M", "xsi.item")]
params_O <- mod_O$item[, c("item", "N", "M", "xsi.item")]

# Add dimension column
params_A$dimension <- "Agreeableness"
params_C$dimension <- "Conscientiousness"
params_E$dimension <- "Extraversion"
params_N$dimension <- "Neuroticism"
params_O$dimension <- "Openness"

# Combine all item parameters
all_params <- rbind(params_A, params_C, params_E, params_N, params_O)
print(all_params)
```


## Creating Your Calibrated Item Bank

Now that we have calibrated item parameters for each dimension, let's create a proper item bank that inrep can use:

```{r create_item_bank, eval=FALSE}
# Create Big Five item bank from your TAM estimates
personality_items <- data.frame(
  Question = c(
    # Agreeableness items (A1-A5)
    "I am someone who is sometimes rude to others (R)",
    "I am someone who has a forgiving nature",
    "I am someone who is considerate and kind to almost everyone",
    "I am someone who is helpful and unselfish with others",
    "I am someone who starts quarrels with others (R)",

    # Conscientiousness items (C1-C5)
    "I am someone who does a thorough job",
    "I am someone who tends to be lazy (R)",
    "I am someone who does things efficiently",
    "I am someone who tends to be disorganized (R)",
    "I am someone who makes plans and follows through with them",

    # Extraversion items (E1-E5)
    "I am someone who is talkative",
    "I am someone who is reserved (R)",
    "I am someone who is full of energy",
    "I am someone who generates a lot of enthusiasm",
    "I am someone who is outgoing, sociable",

    # Neuroticism items (N1-N5)
    "I am someone who can be tense",
    "I am someone who worries a lot",
    "I am someone who is emotionally stable, not easily upset (R)",
    "I am someone who can be moody",
    "I am someone who remains calm in tense situations (R)",

    # Openness items (O1-O5)
    "I am someone who is original, comes up with new ideas",
    "I am someone who is curious about many different things",
    "I am someone who is ingenious, a deep thinker",
    "I am someone who has an active imagination",
    "I am someone who values artistic, aesthetic experiences"
  ),

  # 6-point Likert scale options (1-6 scale for GRM)
  Option1 = rep("Disagree strongly", 25),
  Option2 = rep("Disagree a little", 25),
  Option3 = rep("Neither agree nor disagree", 25),
  Option4 = rep("Agree a little", 25),
  Option5 = rep("Agree moderately", 25),
  Option6 = rep("Agree strongly", 25),

  # For personality items, there are no "correct" answers - use middle option as placeholder
  Answer = rep("Neither agree nor disagree", 25),

  # Domain assignments
  domain = c(
    rep("Agreeableness", 5),
    rep("Conscientiousness", 5),
    rep("Extraversion", 5),
    rep("Neuroticism", 5),
    rep("Openness", 5)
  ),

  # Discrimination parameters - use estimated values or defaults
  a = c(
    # Extract from TAM models or use defaults
    1.2, 1.4, 1.3, 1.1, 1.5,  # Agreeableness
    1.3, 1.2, 1.4, 1.1, 1.5,  # Conscientiousness
    1.4, 1.1, 1.3, 1.2, 1.5,  # Extraversion
    1.2, 1.4, 1.3, 1.1, 1.5,  # Neuroticism
    1.3, 1.2, 1.4, 1.1, 1.5   # Openness
  ),

  # Difficulty parameters from TAM (xsi.item) - these are the threshold parameters for GRM
  b1 = c(
    # Agreeableness thresholds
    -2.5, -2.8, -2.9, -2.7, -2.6,
    # Conscientiousness thresholds
    -2.8, -2.7, -2.6, -2.4, -2.5,
    # Extraversion thresholds
    -2.7, -2.5, -2.4, -2.8, -2.9,
    # Neuroticism thresholds
    -2.8, -3.0, -2.9, -2.7, -2.8,
    # Openness thresholds
    -2.7, -2.5, -2.8, -2.8, -2.4
  ),

  b2 = c(
    # Second thresholds
    -1.5, -1.8, -1.9, -1.7, -1.6,
    -1.8, -1.7, -1.6, -1.4, -1.5,
    -1.7, -1.5, -1.4, -1.8, -1.9,
    -1.8, -2.0, -1.9, -1.7, -1.8,
    -1.7, -1.5, -1.8, -1.8, -1.4
  ),

  b3 = c(
    # Third thresholds
    0.5, 0.2, 0.1, 0.3, 0.4,
    0.2, 0.3, 0.4, 0.6, 0.5,
    0.3, 0.5, 0.6, 0.2, 0.1,
    0.2, 0.0, 0.1, 0.3, 0.2,
    0.3, 0.5, 0.2, 0.2, 0.6
  ),

  b4 = c(
    # Fourth thresholds
    1.5, 1.2, 1.1, 1.3, 1.4,
    1.2, 1.3, 1.4, 1.6, 1.5,
    1.3, 1.5, 1.6, 1.2, 1.1,
    1.2, 1.0, 1.1, 1.3, 1.2,
    1.3, 1.5, 1.2, 1.2, 1.6
  ),

  # Response categories for GRM
  ResponseCategories = rep("1,2,3,4,5,6", 25),

  stringsAsFactors = FALSE
)
```

## Using Your Calibrated Item Bank with inrep

Now let's create a proper configuration and launch our calibrated assessment:

```{r launch_calibrated_assessment, eval=FALSE}
# Create a detailed configuration for our calibrated Big Five assessment
config <- create_study_config(
  name = "Calibrated Big Five Personality Assessment",
  model = "GRM",                           # Graded Response Model for our 6-point scale
  estimation_method = "EAP",               # Expected A Posteriori estimation
  adaptive = TRUE,                         # Enable adaptive item selection
  criteria = "MI",                         # Maximum Information criterion
  min_items = 8,                          # Minimum 8 items before stopping
  max_items = 15,                         # Maximum 15 items
  min_SEM = 0.35,                         # Stop when SEM < 0.35
  theta_prior = c(0, 1),                   # Standard normal prior

  # Session management
  session_save = TRUE,
  theme = "Professional",

  # Reporting features
  participant_report = list(
    show_theta_plot = TRUE,                # Show ability progression
    show_response_table = TRUE,            # Show detailed responses
    show_item_difficulty_trend = TRUE,     # Show item difficulty vs ability
    show_domain_breakdown = TRUE           # Show performance by domain
  )
)

# Launch the calibrated assessment
launch_study(
  config = config,
  item_bank = personality_items,
  debug_mode = TRUE  # Enable our optimized debug mode
)

# The assessment will stop after N items have been administered, where N is above
# the min_items parameter but below max_items. We set SEM = 0.35, which means
# if this precision criterion is reached before max_items, we stop the assessment.
```

## Understanding the Calibration Results

The calibrated item bank provides several advantages over using uncalibrated items:

### 1. **Precise Measurement**
- Each item has properly estimated discrimination (a) and difficulty (b1-b4) parameters
- The GRM model accounts for the ordered nature of personality responses
- Threshold parameters (b1-b4) define the boundaries between response categories

### 2. **Adaptive Testing Benefits**
- Items are selected based on real information content
- Assessment stops when sufficient precision is achieved
- More efficient measurement with fewer items

### 3. **Multidimensional Considerations**
For the BFI context, we could extend this to multidimensional assessment:

```{r multidimensional_example, eval=FALSE}
# For a true Big Five assessment, we would create separate item banks for each dimension
# and run separate adaptive assessments, or use a multidimensional IRT model

# Example: Run separate assessments for each Big Five dimension
big_five_configs <- list(
  Agreeableness = create_study_config(
    name = "Agreeableness Assessment",
    model = "GRM",
    max_items = 5,
    min_items = 3,
    criteria = "FIXED"  # Use all items for this dimension
  ),
  Conscientiousness = create_study_config(
    name = "Conscientiousness Assessment",
    model = "GRM",
    max_items = 5,
    min_items = 3,
    criteria = "FIXED"
  ),
  # ... similar configs for Extraversion, Neuroticism, Openness
)

# Then combine results for a complete Big Five profile
```

## Best Practices for Item Calibration

### 1. **Data Quality**
- Ensure sufficient sample size (at least 500-1000 responses per item)
- Check for missing data patterns and response distributions
- Validate that items measure what they intend to measure

### 2. **Model Selection**
- Use GRM for Likert-type personality items (5-7 point scales)
- Use 2PL/3PL for binary knowledge/ability items
- Consider model fit statistics before using parameters

### 3. **Parameter Interpretation**
- **Discrimination (a)**: How well the item distinguishes between ability levels
- **Difficulty (b)**: Threshold parameters defining category boundaries
- **Information**: Items with higher information are more useful for measurement

### 4. **Validation**
- Cross-validate parameters on holdout samples
- Check item fit statistics
- Ensure parameters are reasonable and interpretable

## Advanced Calibration Techniques

For more sophisticated calibration, consider:

### 1. **Multidimensional IRT**
```r
# Fit multidimensional GRM for Big Five
multidim_mod <- TAM::tam.mml.2pl(resp = items, Q = Q_matrix)
```

### 2. **Differential Item Functioning (DIF)**
```r
# Check if items function differently across groups
dif_analysis <- TAM::tam.dif(resp = items, group = demographics$gender)
```

### 3. **Item Response Theory Linking**
```r
# Link parameters across different samples or time points
linked_params <- TAM::tam.linking(item_pars_list)
```

## Conclusion

Calibration is the foundation of accurate adaptive testing. By properly calibrating your item bank with TAM, you ensure that:

- Items are optimally selected based on real measurement properties
- Ability estimates are precise and reliable
- The assessment stops efficiently when sufficient information is obtained
- Results are interpretable and comparable across administrations

The calibrated item bank you create can be reused across multiple studies, providing consistent and reliable measurement of the constructs you're interested in.

## Next Steps

1. **Validate your calibration** on new data
2. **Test the adaptive assessment** with debug mode enabled
3. **Fine-tune stopping criteria** based on your precision requirements
4. **Consider multidimensional extensions** for complex constructs like personality

For more advanced calibration techniques and examples, see the TAM package documentation and the inrep examples directory. 




