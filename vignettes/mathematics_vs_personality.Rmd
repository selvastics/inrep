---
title: "Comparing Assessment Domains: Mathematics vs Personality"
author: "inrep Package Team"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_depth: 2
    theme: flatly
vignette: >
  %\VignetteIndexEntry{Comparing Assessment Domains: Mathematics vs Personality}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Introduction

This vignette demonstrates how to use the `inrep` package for conducting assessments across different domains: cognitive abilities (mathematics) and personality traits (Big Five Inventory). We'll explore the differences in configuration, administration, and analysis between these two assessment types.

# Dataset Comparison

## Mathematics Items

The mathematics dataset contains 30 items covering four content areas:

```{r eval=FALSE}
library(inrep)
data(math_items)

# Overview of math items
table(math_items$Content_Area)
table(math_items$Difficulty_Level)

# Sample question
print(math_items[1, c("Question", "Option1", "Option2", "Option3", "Option4", "Answer")])
```

**Mathematics Features:**
- **Content Areas**: Arithmetic, Algebra, Geometry, Statistics
- **Difficulty Levels**: Easy, Medium, Hard
- **Response Format**: Multiple choice (4 options)
- **IRT Model**: 2PL (discrimination and difficulty parameters)

## BFI Items

The BFI dataset contains personality assessment items:

```{r eval=FALSE}
# bfi_items is automatically available via LazyData

# Overview of BFI items
table(bfi_items$Content_Area)

# Sample question
print(bfi_items[1, c("Question", "Option1", "Option2", "Option3", "Option4", "Option5")])
```

**BFI Features:**
- **Content Areas**: Extraversion, Agreeableness, Conscientiousness, Neuroticism, Openness
- **Response Format**: Likert scale (5 options)
- **IRT Model**: Graded Response Model (multiple threshold parameters)

# Configuration Differences

## Mathematics Assessment Configuration

```{r eval=FALSE}
# Mathematics adaptive test configuration
math_config <- create_study_config(
  study_name = "Mathematics Adaptive Assessment",
  item_bank = "math_items",
  estimation_method = "TAM",
  
  # Adaptive parameters optimized for cognitive assessment
  adaptive_selection = TRUE,
  selection_method = "maximum_info",
  max_items = 15,
  min_items = 5,
  stopping_criterion = "se_threshold",
  se_threshold = 0.4,
  
  # Content balancing for mathematics
  content_balancing = TRUE,
  content_areas = c("Arithmetic", "Algebra", "Geometry", "Statistics"),
  
  # Demographics relevant to mathematics assessment
  demographics = list(
    grade_level = list(type = "select", options = c("6th", "7th", "8th", "9th", "10th")),
    math_confidence = list(type = "slider", min = 1, max = 10, label = "Math Confidence (1-10)"),
    calculator_use = list(type = "checkbox", label = "Calculator permitted")
  )
)
```

## BFI Assessment Configuration

```{r eval=FALSE}
# BFI personality assessment configuration
bfi_config <- create_study_config(
  study_name = "Big Five Personality Assessment",
  item_bank = "bfi_items",
  estimation_method = "TAM",
  
  # Fixed-length administration for personality
  adaptive_selection = FALSE,
  max_items = 44,  # All BFI items
  randomize_items = TRUE,
  
  # Different stopping criteria for personality
  stopping_criterion = "max_items",
  
  # Demographics relevant to personality assessment
  demographics = list(
    age = list(type = "numeric", required = TRUE, min = 16, max = 100),
    occupation = list(type = "text", required = FALSE),
    personality_interest = list(type = "select", options = c("Research", "Self-knowledge", "Career", "Other"))
  )
)
```

# Assessment Scenarios

## Scenario 1: Educational Mathematics Testing

```{r eval=FALSE}
# Create educational math assessment
educational_math <- create_study_config(
  study_name = "Grade 8 Mathematics Assessment",
  item_bank = "math_items",
  estimation_method = "TAM",
  
  # Adaptive parameters for educational context
  adaptive_selection = TRUE,
  selection_method = "maximum_info",
  max_items = 20,
  min_items = 8,
  stopping_criterion = "se_threshold",
  se_threshold = 0.35,
  
  # Content balancing ensures comprehensive coverage
  content_balancing = TRUE,
  min_items_per_area = 2,
  
  # School-specific demographics
  demographics = list(
    student_id = list(type = "text", required = TRUE),
    grade = list(type = "select", options = c("8")),
    school = list(type = "text", required = TRUE),
    test_accommodation = list(type = "checkbox", label = "Extended time needed")
  ),
  
  # Educational-specific settings
  show_progress = TRUE,
  allow_review = FALSE,
  time_limit = 45  # 45 minutes
)

# Launch educational assessment
launch_study(educational_math)
```

## Scenario 2: Personality Research Study

```{r eval=FALSE}
# Create personality research study
personality_research <- create_study_config(
  study_name = "Personality and Well-being Research",
  item_bank = "bfi_items",
  estimation_method = "TAM",
  
  # Full personality assessment
  adaptive_selection = FALSE,
  max_items = 44,
  randomize_items = TRUE,
  
  # Research-specific demographics
  demographics = list(
    participant_id = list(type = "text", required = TRUE),
    age = list(type = "numeric", required = TRUE, min = 18, max = 80),
    gender = list(type = "select", options = c("Male", "Female", "Non-binary", "Prefer not to say")),
    education = list(type = "select", options = c("High School", "Bachelor", "Master", "PhD")),
    consent = list(type = "checkbox", required = TRUE, label = "I consent to participate")
  ),
  
  # Research settings
  show_progress = TRUE,
  allow_review = True,
  save_partial = TRUE
)

# Launch research study
launch_study(personality_research)
```

## Scenario 3: Combined Assessment

```{r eval=FALSE}
# Create combined cognitive and personality assessment
combined_assessment <- create_study_config(
  study_name = "Comprehensive Assessment Battery",
  item_bank = "combined_items",  # Hypothetical combined dataset
  estimation_method = "TAM",
  
  # Multi-domain adaptive testing
  adaptive_selection = TRUE,
  selection_method = "balanced_info",
  max_items = 35,
  min_items = 20,
  stopping_criterion = "multiple",
  se_threshold = 0.4,
  
  # Domain balancing
  domain_balancing = TRUE,
  domains = c("Mathematics", "Personality"),
  min_items_per_domain = 10,
  
  # Comprehensive demographics
  demographics = list(
    participant_id = list(type = "text", required = TRUE),
    age = list(type = "numeric", required = TRUE),
    education = list(type = "select", options = c("High School", "Bachelor", "Master", "PhD")),
    assessment_purpose = list(type = "select", options = c("Research", "Educational", "Clinical"))
  )
)

# Launch combined assessment
launch_study(combined_assessment)
```

# Analysis Differences

## Mathematics Ability Estimation

```{r eval=FALSE}
# Mathematics ability estimation
math_responses <- c(1, 1, 0, 1, 0, 1, 1, 0, 1, 1)  # Sample responses
math_items_used <- c(1, 5, 8, 12, 15, 18, 22, 25, 28, 30)

math_ability <- estimate_ability(
  responses = math_responses,
  item_indices = math_items_used,
  item_bank = "math_items",
  method = "ML"
)

# Mathematics-specific interpretation
interpret_math_ability <- function(theta) {
  if (theta < -1) return("Below Grade Level")
  if (theta < 0) return("Approaching Grade Level")
  if (theta < 1) return("At Grade Level")
  return("Above Grade Level")
}

cat("Mathematics Ability:", round(math_ability$theta, 2))
cat("Performance Level:", interpret_math_ability(math_ability$theta))
```

## Personality Trait Estimation

```{r eval=FALSE}
# BFI trait estimation (example for Extraversion)
bfi_responses <- c(4, 2, 4, 3, 5, 2, 4, 3, 4, 2)  # Likert scale responses
extraversion_items <- c(1, 6, 11, 16, 21, 26, 31, 36, 41, 46)

extraversion_score <- estimate_ability(
  responses = bfi_responses,
  item_indices = extraversion_items,
  item_bank = "bfi_items",
  method = "ML"
)

# Personality-specific interpretation
interpret_extraversion <- function(theta) {
  if (theta < -1) return("Low Extraversion")
  if (theta < 0) return("Below Average Extraversion")
  if (theta < 1) return("Average Extraversion")
  return("High Extraversion")
}

cat("Extraversion Level:", round(extraversion_score$theta, 2))
cat("Interpretation:", interpret_extraversion(extraversion_score$theta))
```

# Reporting and Visualization

## Mathematics Report

```{r eval=FALSE}
# Create mathematics assessment report
create_math_report <- function(ability_est, items_used, responses) {
  # Calculate content area performance
  content_performance <- aggregate(responses, 
                                 by = list(math_items$Content_Area[items_used]), 
                                 mean)
  
  # Create report
  report <- list(
    overall_ability = ability_est$theta,
    se_estimate = ability_est$se,
    items_administered = length(items_used),
    content_performance = content_performance,
    recommendations = generate_math_recommendations(ability_est$theta)
  )
  
  return(report)
}

generate_math_recommendations <- function(theta) {
  if (theta < -1) {
    return("Focus on basic arithmetic and number operations")
  } else if (theta < 0) {
    return("Practice word problems and basic algebra")
  } else if (theta < 1) {
    return("Work on geometry and statistics concepts")
  } else {
    return("Ready for advanced mathematics topics")
  }
}

# Generate mathematics report
math_report <- create_math_report(math_ability, math_items_used, math_responses)
print(math_report)
```

## Personality Report

```{r eval=FALSE}
# Create personality assessment report
create_personality_report <- function(trait_scores) {
  # Assuming trait_scores is a named vector of Big Five scores
  
  # Create personality profile
  profile <- data.frame(
    Trait = names(trait_scores),
    Score = trait_scores,
    Percentile = pnorm(trait_scores) * 100,
    Interpretation = sapply(trait_scores, interpret_trait_score)
  )
  
  # Generate narrative report
  narrative <- generate_personality_narrative(trait_scores)
  
  report <- list(
    trait_profile = profile,
    narrative = narrative,
    recommendations = generate_personality_recommendations(trait_scores)
  )
  
  return(report)
}

interpret_trait_score <- function(score) {
  if (score < -1) return("Low")
  if (score < -0.5) return("Below Average")
  if (score < 0.5) return("Average")
  if (score < 1) return("Above Average")
  return("High")
}

generate_personality_narrative <- function(scores) {
  # Create personalized narrative based on trait scores
  # This would be more sophisticated in practice
  paste("Based on your responses, you show", 
        interpret_trait_score(scores["Extraversion"]), "levels of extraversion,",
        interpret_trait_score(scores["Conscientiousness"]), "conscientiousness,",
        "and", interpret_trait_score(scores["Openness"]), "openness to experience.")
}

# Generate personality report
personality_report <- create_personality_report(trait_scores)
print(personality_report)
```

# Best Practices by Domain

## Mathematics Assessment Best Practices

1. **Content Balancing**: Ensure coverage across all mathematical domains
2. **Adaptive Termination**: Use SE thresholds appropriate for educational decisions
3. **Item Exposure**: Protect high-value items from overexposure
4. **Feedback**: Provide immediate feedback on performance
5. **Accommodations**: Support students with special needs

## Personality Assessment Best Practices

1. **Complete Administration**: Typically use all items for comprehensive assessment
2. **Response Honesty**: Encourage honest responding through appropriate instructions
3. **Cultural Sensitivity**: Consider cultural factors in interpretation
4. **Confidentiality**: Ensure privacy and confidentiality of results
5. **Professional Interpretation**: Use qualified professionals for clinical interpretations

# Integration Strategies

## Cross-Domain Analysis

```{r eval=FALSE}
# Analyze relationships between mathematics ability and personality traits
analyze_cross_domain <- function(math_ability, personality_traits) {
  # Calculate correlations
  correlations <- cor(c(math_ability), personality_traits)
  
  # Identify significant relationships
  significant_corr <- correlations[abs(correlations) > 0.3]
  
  # Generate insights
  insights <- generate_cross_domain_insights(math_ability, personality_traits)
  
  return(list(
    correlations = correlations,
    significant_relationships = significant_corr,
    insights = insights
  ))
}

generate_cross_domain_insights <- function(math_ability, traits) {
  insights <- character()
  
  # Example insights based on research
  if (traits["Conscientiousness"] > 0.5 && math_ability > 0) {
    insights <- c(insights, "High conscientiousness supports strong math performance")
  }
  
  if (traits["Openness"] > 0.5 && math_ability > 0.5) {
    insights <- c(insights, "Openness to experience facilitates advanced math learning")
  }
  
  return(insights)
}
```

## Comprehensive Reporting

```{r eval=FALSE}
# Create comprehensive report combining both domains
create_comprehensive_report <- function(math_results, personality_results) {
  report <- list(
    assessment_date = Sys.Date(),
    cognitive_domain = list(
      mathematics = math_results,
      interpretation = "Mathematics performance indicators",
      recommendations = generate_math_recommendations(math_results$theta)
    ),
    personality_domain = list(
      big_five = personality_results,
      interpretation = "Personality trait profile",
      recommendations = generate_personality_recommendations(personality_results)
    ),
    integrated_analysis = analyze_cross_domain(math_results$theta, personality_results)
  )
  
  return(report)
}

# Generate comprehensive report
comprehensive_report <- create_comprehensive_report(math_results, personality_results)
print(comprehensive_report)
```

# Conclusion

The `inrep` package provides flexible tools for conducting assessments across different domains. While mathematics assessments typically use adaptive testing for efficiency, personality assessments often benefit from comprehensive fixed-length administration. Understanding these differences allows for optimal configuration and interpretation of results.

Key takeaways:
- **Mathematics**: Focus on adaptive efficiency and content balancing
- **Personality**: Emphasize comprehensive coverage and honest responding
- **Combined**: Balance efficiency with comprehensive assessment goals

The package's flexibility allows researchers and practitioners to tailor assessments to their specific needs while maintaining psychometric rigor.
