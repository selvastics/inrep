---
title: "The Complete Guide to inrep: Interactive Adaptive Testing in R"
subtitle: "Building Professional Assessments with Item Response Theory"
author: "inrep Development Team"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_document:
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: false
      smooth_scroll: true
    number_sections: true
    theme: cosmo
    highlight: tango
    code_folding: show
    df_print: paged
    css: styles.css
vignette: >
  %\VignetteIndexEntry{The Complete Guide to inrep}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 8,
  fig.height = 6,
  fig.align = "center",
  out.width = "90%",
  warning = FALSE,
  message = FALSE,
  echo = TRUE
)

# Load required packages
library(inrep)
library(ggplot2)
library(dplyr)
library(knitr)
library(DT)

# Set theme for plots
theme_set(theme_minimal(base_size = 12))
```

# Introduction: Welcome to inrep {#intro}

## What is inrep?

**inrep** (Interactive Response Evaluation Platform) is a comprehensive R package for creating, administering, and analyzing adaptive assessments using Item Response Theory (IRT). It provides a complete ecosystem for psychological testing, educational assessment, and survey research.

### Core Philosophy

inrep is built on three pillars:

1. **Accessibility**: Making IRT-based testing accessible to researchers without extensive psychometric background
2. **Flexibility**: Supporting both adaptive and fixed-form assessments with multiple IRT models
3. **Professional Quality**: Production-ready code with enterprise features

## Why Choose inrep?

```{r features-table, echo=FALSE}
features <- data.frame(
  Feature = c("IRT Models", "UI Themes", "Languages", "Question Types", 
              "Export Formats", "Security Features"),
  Support = c("1PL, 2PL, 3PL, GRM, PCM, RSM", 
              "10+ Built-in Themes", 
              "English, German, Spanish, French",
              "30+ Types", 
              "CSV, JSON, SPSS, PDF",
              "GDPR, Encryption, Rate Limiting"),
  stringsAsFactors = FALSE
)
kable(features, caption = "inrep Feature Overview")
```

# Quick Start: Your First inrep Study {#quickstart}

## Basic Adaptive Assessment

Let's launch your first adaptive assessment in just a few lines:

```{r first-study, eval=FALSE}
library(inrep)

# Load built-in item bank
data(bfi_items)

# Create configuration for adaptive testing
config <- create_study_config(
  name = "My First Adaptive Test",
  model = "GRM",           # Graded Response Model
  max_items = 10,          # Maximum 10 items
  min_SEM = 0.3,          # Stop when SEM < 0.3
  theme = "professional"   # Professional theme
)

# Launch the study
launch_study(config, bfi_items)
```

### What Happens Behind the Scenes?

When you run `launch_study()`, inrep:

1. **Initializes** the Shiny application with your configuration
2. **Loads** the item bank and validates parameters
3. **Presents** the consent and demographic forms (if configured)
4. **Administers** items adaptively based on responses
5. **Calculates** ability estimates in real-time
6. **Generates** comprehensive results and visualizations

## Non-Adaptive (Fixed) Assessment

For traditional questionnaires with fixed item order:

```{r fixed-study, eval=FALSE}
# Configuration for non-adaptive testing
config_fixed <- create_study_config(
  name = "Personality Questionnaire",
  adaptive = FALSE,        # Disable adaptive testing
  max_items = 5,          # Show exactly 5 items
  theme = "hildesheim",   # University theme
  progress_style = "bar"  # Progress bar display
)

# Launch fixed assessment
launch_study(config_fixed, bfi_items)
```

# Understanding Study Configurations {#configurations}

## Essential Parameters

The `create_study_config()` function is your gateway to customizing assessments:

```{r config-essential}
# Minimal configuration
minimal_config <- create_study_config(
  name = "Quick Assessment"
)

# View default settings
str(minimal_config[1:10])  # First 10 settings
```

## Advanced Configuration

```{r config-advanced, eval=FALSE}
# Comprehensive configuration
advanced_config <- create_study_config(
  # Basic Information
  name = "Advanced Personality Assessment",
  
  # IRT Settings
  model = "GRM",                    # IRT model
  estimation_method = "EAP",        # Estimation engine
  
  # Adaptive Testing Parameters
  adaptive = TRUE,                  # Enable adaptive testing
  min_items = 5,                    # Minimum items
  max_items = 20,                   # Maximum items
  min_SEM = 0.25,                  # Stopping criterion
  criteria = "MI",                  # Maximum Information
  
  # User Interface
  theme = "ocean",                  # Ocean theme
  language = "en",                  # English
  progress_style = "circle",        # Circular progress
  
  # Demographics
  demographics = c("Age", "Gender", "Education"),
  
  # Session Management
  session_save = TRUE,              # Enable recovery
  max_session_duration = 60,        # 60 minutes timeout
  
  # Features
  feedback_enabled = TRUE,          # Item feedback
  show_introduction = TRUE,         # Introduction page
  show_consent = TRUE,              # Consent form
  show_gdpr_compliance = TRUE,      # GDPR compliance
  
  # Performance
  cache_enabled = TRUE,             # Cache calculations
  parallel_computation = FALSE      # Single-threaded
)
```

# Item Response Theory in inrep {#irt}

## Supported IRT Models

inrep implements multiple IRT models for different assessment needs:

### 1-Parameter Logistic (1PL) Model

```{r irt-1pl, eval=FALSE}
# 1PL: All items have same discrimination
config_1pl <- create_study_config(
  name = "Knowledge Test",
  model = "1PL",
  max_items = 15
)

# Launch with appropriate item bank
launch_study(config_1pl, knowledge_items)
```

### 2-Parameter Logistic (2PL) Model

```{r irt-2pl, eval=FALSE}
# 2PL: Items vary in discrimination and difficulty
config_2pl <- create_study_config(
  name = "Ability Assessment",
  model = "2PL",
  min_SEM = 0.3
)

launch_study(config_2pl, ability_items)
```

### Graded Response Model (GRM)

```{r irt-grm}
# GRM: For polytomous (Likert-scale) items
config_grm <- create_study_config(
  name = "Personality Assessment",
  model = "GRM",
  max_items = 10
)

# View model specifications
cat("Model:", config_grm$model, "\n")
cat("Estimation:", config_grm$estimation_method, "\n")
```

## Item Selection Algorithms

inrep uses sophisticated algorithms for adaptive item selection:

```{r item-selection-demo}
# Different selection criteria
criteria_options <- c("MI", "RANDOM", "WEIGHTED", "MFI")

# Create configs with different criteria
configs <- lapply(criteria_options, function(crit) {
  create_study_config(
    name = paste("Test with", crit),
    criteria = crit,
    max_items = 10
  )
})

# Display criteria comparison
criteria_df <- data.frame(
  Criterion = criteria_options,
  Description = c(
    "Maximum Information at current theta",
    "Random selection from available items",
    "Weighted by information and exposure",
    "Maximum Fisher Information"
  ),
  Best_For = c(
    "Precision testing",
    "Item exposure control",
    "Balanced assessment",
    "Research studies"
  )
)
kable(criteria_df, caption = "Item Selection Criteria")
```

# Launching Studies with Different Themes {#themes}

## Available Themes Gallery

inrep includes beautiful, professional themes:

```{r themes-gallery, eval=FALSE}
# List of available themes
themes <- c("light", "professional", "ocean", "forest", 
            "midnight", "sunset", "hildesheim")

# Launch study with each theme
for (theme in themes) {
  config <- create_study_config(
    name = paste("Demo -", theme, "theme"),
    theme = theme,
    max_items = 3
  )
  
  # Each launch opens in a new window
  launch_study(config, bfi_items[1:10,])
  
  Sys.sleep(2)  # Brief pause between launches
}
```

## Custom Theme Example

```{r custom-theme, eval=FALSE}
# Configuration with custom styling
config_custom <- create_study_config(
  name = "Custom Styled Assessment",
  theme = "professional"
)

# Add custom CSS through the launch
launch_study(
  config_custom, 
  bfi_items,
  custom_css = "
    .question-text { 
      font-size: 1.2em; 
      color: #2c3e50;
    }
    .btn-primary {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
  "
)
```

# Real-Time Visualizations {#visualizations}

## Ability Tracking Plot

During adaptive testing, inrep generates real-time ability estimates:

```{r ability-plot-demo}
# Simulate ability tracking data
set.seed(123)
n_items <- 10
theta_history <- cumsum(rnorm(n_items, 0, 0.3))
se_history <- 1 / sqrt(1:n_items)

# Create ability tracking plot
ability_df <- data.frame(
  Item = 1:n_items,
  Theta = theta_history,
  SE = se_history,
  Lower = theta_history - 1.96 * se_history,
  Upper = theta_history + 1.96 * se_history
)

ggplot(ability_df, aes(x = Item)) +
  geom_ribbon(aes(ymin = Lower, ymax = Upper), 
              fill = "steelblue", alpha = 0.3) +
  geom_line(aes(y = Theta), color = "steelblue", size = 1.5) +
  geom_point(aes(y = Theta), color = "steelblue", size = 3) +
  labs(
    title = "Real-Time Ability Estimation in inrep",
    subtitle = "Theta estimates with 95% confidence intervals",
    x = "Item Number",
    y = "Ability Estimate (Î¸)"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold"),
    panel.grid.minor = element_blank()
  )
```

## Information Function Plot

Visualizing test information across the ability range:

```{r info-plot-demo}
# Simulate test information function
theta_range <- seq(-4, 4, 0.1)
info <- dnorm(theta_range, 0, 1.5) * 10

info_df <- data.frame(
  Theta = theta_range,
  Information = info
)

ggplot(info_df, aes(x = Theta, y = Information)) +
  geom_area(fill = "coral", alpha = 0.7) +
  geom_line(color = "darkred", size = 1.2) +
  labs(
    title = "Test Information Function",
    subtitle = "Information provided across ability levels",
    x = "Ability (Î¸)",
    y = "Information"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold"),
    panel.grid.minor = element_blank()
  )
```

## Response Pattern Analysis

```{r response-pattern}
# Simulate response patterns
set.seed(456)
n_participants <- 50
n_items <- 10

responses <- matrix(
  sample(1:5, n_participants * n_items, replace = TRUE),
  nrow = n_participants
)

# Calculate item means
item_means <- colMeans(responses)
item_df <- data.frame(
  Item = paste("Item", 1:n_items),
  Mean = item_means,
  SD = apply(responses, 2, sd)
)

ggplot(item_df, aes(x = Item, y = Mean)) +
  geom_col(fill = "darkgreen", alpha = 0.7) +
  geom_errorbar(aes(ymin = Mean - SD, ymax = Mean + SD), 
                width = 0.3, color = "darkgreen") +
  labs(
    title = "Item Response Patterns",
    subtitle = "Mean responses with standard deviations",
    x = "Item",
    y = "Mean Response"
  ) +
  coord_flip() +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold"),
    panel.grid.minor = element_blank()
  )
```

# Working with Item Banks {#itembanks}

## Understanding Item Bank Structure

```{r itembank-structure}
# Load and examine the built-in item bank
data(bfi_items)

# Display structure
cat("Item bank dimensions:", dim(bfi_items), "\n")
cat("Required columns:", paste(names(bfi_items)[1:5], collapse = ", "), "\n")

# Show first few items
kable(head(bfi_items[, c("Question", "a", "b1", "b2")], 3),
      caption = "Sample Items from BFI Item Bank")
```

## Creating Custom Item Banks

```{r custom-itembank}
# Create a custom item bank for ability testing
custom_items <- data.frame(
  Question = c(
    "I can solve complex problems easily",
    "I enjoy intellectual challenges",
    "I learn new concepts quickly",
    "I think abstractly",
    "I analyze situations thoroughly"
  ),
  a = c(1.2, 1.5, 1.8, 1.3, 1.6),  # Discrimination
  b = c(-0.5, 0.0, 0.5, 1.0, 1.5),  # Difficulty
  content = rep("cognitive", 5),
  stringsAsFactors = FALSE
)

# Display custom item bank
kable(custom_items, caption = "Custom Cognitive Ability Items")
```

## Launching Study with Custom Items

```{r custom-launch, eval=FALSE}
# Configure for custom items
custom_config <- create_study_config(
  name = "Cognitive Ability Test",
  model = "2PL",  # 2PL model for ability items
  max_items = 5,
  theme = "professional"
)

# Launch with custom item bank
launch_study(custom_config, custom_items)
```

# Multi-Language Support {#languages}

## Configuring Language Settings

```{r language-config}
# Supported languages
languages <- c("en", "de", "es", "fr")
language_names <- c("English", "German", "Spanish", "French")

# Create configurations for each language
lang_configs <- Map(function(code, name) {
  create_study_config(
    name = paste("Assessment in", name),
    language = code,
    max_items = 5
  )
}, languages, language_names)

# Display language options
lang_df <- data.frame(
  Code = languages,
  Language = language_names,
  Welcome = c("Welcome", "Willkommen", "Bienvenido", "Bienvenue"),
  Start = c("Start", "Starten", "Comenzar", "Commencer")
)
kable(lang_df, caption = "Multi-Language Support")
```

## Launching Bilingual Study

```{r bilingual-study, eval=FALSE}
# German language configuration
config_de <- create_study_config(
  name = "PersÃ¶nlichkeitsbewertung",
  language = "de",
  demographics = c("Alter", "Geschlecht", "Bildung"),
  theme = "professional",
  max_items = 10
)

# Launch German version
launch_study(config_de, bfi_items)
```

# Session Management and Recovery {#sessions}

## Enabling Session Persistence

```{r session-config}
# Configuration with full session management
session_config <- create_study_config(
  name = "Long Assessment with Recovery",
  session_save = TRUE,              # Enable saving
  max_session_duration = 120,       # 2 hours
  max_response_time = 300,          # 5 min per item
  show_session_time = TRUE          # Display timer
)

# Display session settings
session_settings <- data.frame(
  Setting = c("Auto-save", "Max Duration", "Item Timeout", "Show Timer"),
  Value = c("Enabled", "120 minutes", "5 minutes", "Yes"),
  Purpose = c(
    "Recover from crashes",
    "Prevent endless sessions",
    "Skip unresponsive items",
    "User awareness"
  )
)
kable(session_settings, caption = "Session Management Features")
```

## Recovery Demonstration

```{r recovery-demo, eval=FALSE}
# Launch study with recovery enabled
recovery_config <- create_study_config(
  name = "Recoverable Assessment",
  session_save = TRUE,
  max_items = 20
)

# If browser crashes or closes, participants can resume
launch_study(recovery_config, bfi_items)

# The session ID and progress are automatically saved
# Reopening the link continues from last item
```

# Advanced Features {#advanced}

## Professional Survey Features

```{r survey-features, eval=FALSE}
# Initialize professional survey features
survey_config <- create_study_config(
  name = "Enterprise Survey",
  max_items = 30
)

# Add survey capabilities
survey <- create_survey(
  config = survey_config,
  
  # Question types
  question_types = c("single", "multiple", "matrix", 
                     "slider", "ranking", "open"),
  
  # Logic and flow
  branching_logic = TRUE,
  randomization = TRUE,
  piping = TRUE,
  
  # Participant management
  panel_management = TRUE,
  quota_control = TRUE,
  
  # Data handling
  export_formats = c("spss", "csv", "json"),
  real_time_stats = TRUE
)

# Launch professional survey
launch_study(survey$config, survey$items)
```

## Adaptive Testing with Constraints

```{r constrained-cat, eval=FALSE}
# Content-balanced adaptive testing
balanced_config <- create_study_config(
  name = "Balanced Adaptive Test",
  adaptive = TRUE,
  
  # Content constraints
  item_groups = list(
    "Verbal" = 1:20,
    "Quantitative" = 21:40,
    "Spatial" = 41:60
  ),
  
  # Ensure balanced selection
  criteria = "WEIGHTED",
  
  # Custom stopping rule
  stopping_rule = function(theta, se, n_items, rv) {
    # Stop if SE < 0.3 OR balanced content
    if (se < 0.3) return(TRUE)
    
    # Check content balance
    verbal <- sum(rv$administered %in% 1:20)
    quant <- sum(rv$administered %in% 21:40)
    spatial <- sum(rv$administered %in% 41:60)
    
    # Stop if each area has 5+ items
    if (all(c(verbal, quant, spatial) >= 5)) return(TRUE)
    
    return(FALSE)
  }
)

launch_study(balanced_config, combined_items)
```

## Custom Recommendation Engine

```{r recommendations}
# Create recommendation function
generate_recommendations <- function(theta, demographics, responses) {
  # Categorize ability level
  level <- cut(theta, 
               breaks = c(-Inf, -1, 0, 1, Inf),
               labels = c("Developing", "Emerging", 
                         "Proficient", "Advanced"))
  
  # Generate personalized recommendations
  recommendations <- switch(as.character(level),
    "Developing" = list(
      "Focus on foundational skills",
      "Practice basic concepts daily",
      "Seek additional support"
    ),
    "Emerging" = list(
      "Build on current knowledge",
      "Challenge yourself gradually",
      "Join study groups"
    ),
    "Proficient" = list(
      "Explore advanced topics",
      "Help others learn",
      "Set higher goals"
    ),
    "Advanced" = list(
      "Pursue specialized training",
      "Lead learning initiatives",
      "Mentor others"
    )
  )
  
  return(recommendations)
}

# Configure with recommendations
config_with_rec <- create_study_config(
  name = "Assessment with Feedback",
  recommendation_fun = generate_recommendations,
  max_items = 10
)
```

# Data Export and Analysis {#analysis}

## Exporting Results

```{r export-demo, eval=FALSE}
# Configure multiple export formats
export_config <- create_study_config(
  name = "Research Study",
  report_formats = c("csv", "json", "rds", "pdf"),
  session_save = TRUE
)

# After assessment completion, data is available in multiple formats
launch_study(export_config, bfi_items)

# Results are automatically saved to:
# - results/study_[timestamp].csv
# - results/study_[timestamp].json
# - results/study_[timestamp].rds
# - results/study_[timestamp].pdf
```

## Analyzing Assessment Data

```{r analysis-demo}
# Simulate assessment results
set.seed(789)
n_participants <- 100

results <- data.frame(
  participant_id = 1:n_participants,
  theta = rnorm(n_participants, 0, 1),
  se = runif(n_participants, 0.2, 0.5),
  n_items = sample(5:20, n_participants, replace = TRUE),
  duration = rpois(n_participants, 15)
)

# Summary statistics
summary_stats <- results %>%
  summarise(
    N = n(),
    Mean_Theta = mean(theta),
    SD_Theta = sd(theta),
    Mean_SE = mean(se),
    Mean_Items = mean(n_items),
    Mean_Duration = mean(duration)
  )

kable(summary_stats, digits = 3, 
      caption = "Assessment Results Summary")

# Distribution plot
ggplot(results, aes(x = theta)) +
  geom_histogram(bins = 20, fill = "steelblue", alpha = 0.7) +
  geom_density(aes(y = ..count..), color = "darkblue", size = 1) +
  labs(
    title = "Distribution of Ability Estimates",
    subtitle = paste("N =", n_participants, "participants"),
    x = "Ability (Î¸)",
    y = "Count"
  ) +
  theme_minimal(base_size = 12)
```

# Best Practices {#bestpractices}

## Assessment Design Guidelines

```{r best-practices}
# Best practices checklist
practices <- data.frame(
  Category = c(
    "Item Bank",
    "Item Bank",
    "Configuration",
    "Configuration",
    "User Experience",
    "User Experience",
    "Data Security",
    "Data Security"
  ),
  Practice = c(
    "Minimum 20 items for adaptive testing",
    "Validate psychometric properties",
    "Set appropriate stopping criteria",
    "Enable session recovery",
    "Provide clear instructions",
    "Test on multiple devices",
    "Enable GDPR compliance",
    "Use secure connections (HTTPS)"
  ),
  Importance = c(
    "Critical",
    "Critical",
    "High",
    "High",
    "Medium",
    "Medium",
    "Critical",
    "Critical"
  )
)

kable(practices, caption = "Assessment Best Practices")
```

## Performance Optimization

```{r performance-tips, eval=FALSE}
# Optimized configuration for large-scale deployment
optimized_config <- create_study_config(
  name = "High-Performance Assessment",
  
  # Performance settings
  cache_enabled = TRUE,           # Cache calculations
  parallel_computation = TRUE,     # Use multiple cores
  
  # Efficient item selection
  criteria = "MI",                 # Fast selection
  theta_grid = seq(-3, 3, 0.2),   # Coarser grid
  
  # Limit resource usage
  max_items = 15,                  # Reasonable maximum
  max_session_duration = 30,       # 30-minute limit
  
  # Minimal UI updates
  progress_style = "minimal",      # Simple progress
  feedback_enabled = FALSE         # No item feedback
)

launch_study(optimized_config, bfi_items)
```

# Troubleshooting {#troubleshooting}

## Common Issues and Solutions

```{r troubleshooting-table}
issues <- data.frame(
  Issue = c(
    "Study won't launch",
    "Items not displaying",
    "Session lost",
    "Slow performance"
  ),
  Cause = c(
    "Missing dependencies",
    "Invalid item bank format",
    "Session timeout",
    "Large item bank"
  ),
  Solution = c(
    "Run: install.packages(c('shiny', 'TAM', 'ggplot2'))",
    "Check required columns: Question, a, b",
    "Enable session_save = TRUE",
    "Enable cache_enabled = TRUE"
  )
)

kable(issues, caption = "Troubleshooting Guide")
```

## Debugging Tools

```{r debugging, eval=FALSE}
# Enable verbose logging
debug_config <- create_study_config(
  name = "Debug Test",
  verbose = TRUE,  # Enable logging
  debug_mode = TRUE  # Show technical details
)

# Check configuration validity
validate_config(debug_config)

# Test item bank compatibility
validate_item_bank(bfi_items, model = "GRM")

# Dry run without launching UI
test_selection <- select_next_item(
  rv = list(administered = c(1, 2, 3), 
            current_ability = 0.5),
  item_bank = bfi_items,
  config = debug_config
)
```

# Complete Examples {#examples}

## Example 1: Educational Assessment

```{r edu-example, eval=FALSE}
# Complete educational assessment setup
edu_config <- create_study_config(
  name = "Mathematics Proficiency Test",
  
  # Educational settings
  model = "2PL",
  adaptive = TRUE,
  min_items = 10,
  max_items = 30,
  min_SEM = 0.25,
  
  # Student information
  demographics = c("Grade", "School", "Teacher"),
  
  # Features for education
  feedback_enabled = TRUE,
  show_introduction = TRUE,
  show_debriefing = TRUE,
  
  # Reporting
  report_formats = c("pdf", "csv"),
  
  # Custom feedback
  recommendation_fun = function(theta, demo, resp) {
    if (theta > 1) {
      return("Advanced: Consider enrichment activities")
    } else if (theta > -1) {
      return("On Track: Continue regular curriculum")
    } else {
      return("Needs Support: Additional practice recommended")
    }
  }
)

# Launch educational assessment
launch_study(edu_config, math_items)
```

## Example 2: Clinical Screening

```{r clinical-example, eval=FALSE}
# Clinical depression screening
clinical_config <- create_study_config(
  name = "Depression Screening Tool",
  
  # Clinical parameters
  model = "GRM",
  min_items = 8,
  max_items = 15,
  min_SEM = 0.4,
  
  # Clinical features
  demographics = c("Age", "Gender", "Treatment_History"),
  show_consent = TRUE,
  show_gdpr_compliance = TRUE,
  
  # Safety features
  response_validation_fun = function(response) {
    # Validate response range
    if (!response %in% 0:3) return(FALSE)
    return(TRUE)
  },
  
  # Clinical recommendations
  recommendation_fun = function(theta, demo, resp) {
    if (theta > 2) {
      return("Severe: Immediate clinical consultation recommended")
    } else if (theta > 1) {
      return("Moderate: Consider professional support")
    } else if (theta > 0) {
      return("Mild: Monitor symptoms")
    } else {
      return("Minimal: No intervention needed")
    }
  }
)

launch_study(clinical_config, depression_items)
```

## Example 3: Research Study

```{r research-example, eval=FALSE}
# Comprehensive research study
research_config <- create_study_config(
  name = "Personality and Cognition Study",
  
  # Research design
  model = "GRM",
  adaptive = TRUE,
  estimation_method = "TAM",
  
  # Comprehensive data collection
  demographics = c("Age", "Gender", "Education", 
                  "Occupation", "Income"),
  
  # Research features
  session_save = TRUE,
  cache_enabled = TRUE,
  parallel_computation = TRUE,
  
  # Multiple phases
  study_phases = c("introduction", "briefing", "consent", 
                  "demographics", "survey", "debriefing"),
  
  # Data export
  report_formats = c("rds", "csv", "json", "spss"),
  
  # Advanced stopping
  stopping_rule = function(theta, se, n, rv) {
    # Complex stopping logic
    if (n >= 40) return(TRUE)  # Hard maximum
    if (n >= 20 && se < 0.3) return(TRUE)  # Precision reached
    if (n >= 10 && se < 0.2) return(TRUE)  # High precision
    return(FALSE)
  }
)

# Launch research study
launch_study(research_config, combined_items)
```

# Conclusion {#conclusion}

## The Power of inrep

With inrep, you can:

- â Create professional adaptive assessments in minutes
- â Support multiple languages and themes
- â Implement various IRT models
- â Generate real-time visualizations
- â Export data in multiple formats
- â Ensure GDPR compliance
- â Recover from session interruptions
- â Scale from research to enterprise

## Getting Help

- **Documentation**: `?inrep` or `vignette("inrep")`
- **GitHub**: Report issues and contribute
- **Examples**: Run `example("launch_study")`

## Start Your Assessment Journey

```{r final-launch, eval=FALSE}
# Your journey starts here
library(inrep)
data(bfi_items)

# Create your first professional assessment
my_config <- create_study_config(
  name = "My Professional Assessment",
  theme = "professional",
  max_items = 10
)

# Launch and see the magic
launch_study(my_config, bfi_items)
```

---

*Thank you for choosing inrep for your assessment needs!*

```{r session-info}
sessionInfo()
```