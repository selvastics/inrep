---
title: "Getting Started with inrep"
author: "Clievins Selva"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting Started with inrep}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

## Introduction

The **inrep** package provides a comprehensive framework for adaptive testing using Item Response Theory (IRT) models. This vignette will guide you through the basic usage of the package, from setting up your first adaptive test to collecting and analyzing results.

## Installation

Install the development version from GitHub:

```{r}
# Install from GitHub
devtools::install_github("selvastics/inrep")
```

Load the package:

```{r}
library(inrep)
```

## Basic Concepts

### Item Response Theory (IRT)
IRT is a framework for designing, analyzing, and scoring tests based on the assumption that the probability of a correct response depends on the respondent's ability and item characteristics.

### Adaptive Testing
Adaptive testing selects items in real-time based on the respondent's previous answers, making tests more efficient and precise.

### TAM Integration
All psychometric computations in **inrep** are performed by the TAM package.

## Quick Start Example

### 1. Load Sample Data

**inrep** includes sample item banks for demonstration:

```{r}
# Load Big Five Inventory personality items
if (!exists("bfi_items")) data(bfi_items)

# Examine the structure
head(bfi_items)
str(bfi_items)
```

### 2. Validate Your Item Bank

Before using an item bank, validate it for TAM compatibility:

```{r}
# Validate for GRM model
is_valid <- validate_item_bank(bfi_items, model = "GRM")

if (is_valid) {
  cat("Item bank is ready for use!\\n")
} else {
  cat("Item bank needs fixes before use.\\n")
}
```

### 3. Create Study Configuration

Configure your adaptive test parameters:

```{r}
# Basic configuration for personality assessment
config <- create_study_config(
  name = "Big Five Personality Assessment",
  model = "GRM",                    # Graded Response Model
  max_items = 20,                   # Maximum items per participant
  min_items = 5,                    # Minimum items per participant
  min_SEM = 0.4,                    # Stop when SEM drops below 0.4
  demographics = c("Age", "Gender", "Education"),
  language = "en",                  # English interface
  theme = "professional"            # Professional appearance
)
```

### 4. Launch the Adaptive Test

Start the interactive Shiny application:

```{r}
# Launch the study
launch_study(config, bfi_items)
```

This opens a web browser with your adaptive test interface where participants can:
- Read consent information
- Complete demographic questions
- Take the adaptive test
- View their results

## Study Configuration Options

### IRT Models

**inrep** supports multiple IRT models:

```{r}
# 1-Parameter Logistic (Rasch) Model
config_1pl <- create_study_config(
  name = "Reading Assessment",
  model = "1PL"
)

# 2-Parameter Logistic Model
config_2pl <- create_study_config(
  name = "Math Assessment", 
  model = "2PL"
)

# 3-Parameter Logistic Model
config_3pl <- create_study_config(
  name = "Multiple Choice Test",
  model = "3PL"
)

# Graded Response Model (for Likert scales)
config_grm <- create_study_config(
  name = "Personality Assessment",
  model = "GRM"
)
```

### Stopping Rules

Control when the adaptive test ends:

```{r}
config <- create_study_config(
  name = "Precise Assessment",
  max_items = 30,          # Never exceed 30 items
  min_items = 10,          # Always give at least 10 items
  min_SEM = 0.3,          # Stop when precision is high (SEM < 0.3)
  max_time = 1800         # Stop after 30 minutes
)
```

### Item Selection

Choose how items are selected:

```{r}
config <- create_study_config(
  name = "Adaptive Test",
  item_selection = "maximum_information",  # Most informative items
  # Other options: "random", "fixed_sequence"
  content_balancing = TRUE,               # Balance content areas
  exposure_control = 0.2                  # Limit item overuse
)
```

## Working with Different Item Banks

### Mathematics Items

```{r}
# Load mathematics assessment items
data(math_items)

# Validate for 2PL model
validate_item_bank(math_items, model = "2PL")

# Configure mathematics assessment
math_config <- create_study_config(
  name = "Mathematics Assessment",
  model = "2PL",
  max_items = 25,
  min_SEM = 0.4,
  demographics = c("Grade", "School"),
  language = "en"
)

# Launch mathematics test
launch_study(math_config, math_items)
```

### Custom Item Banks

Create your own item bank:

```{r}
# Example: Simple knowledge test
custom_items <- data.frame(
  Question = c(
    "What is the capital of France?",
    "Who wrote Romeo and Juliet?",
    "What is 2 + 2?"
  ),
  a = c(1.2, 0.9, 1.5),           # Discrimination parameters
  b = c(0.0, 0.5, -1.0),          # Difficulty parameters
  Option1 = c("London", "Shakespeare", "3"),
  Option2 = c("Paris", "Dickens", "4"),
  Option3 = c("Berlin", "Austen", "5"),
  Option4 = c("Madrid", "Hemingway", "6"),
  Answer = c("Paris", "Shakespeare", "4")
)

# Validate custom item bank
validate_item_bank(custom_items, model = "2PL")

# Configure and launch
custom_config <- create_study_config(
  name = "General Knowledge Test",
  model = "2PL"
)

launch_study(custom_config, custom_items)
```

## Multilingual Support

**inrep** supports multiple languages:

```{r}
# German interface
config_de <- create_study_config(
  name = "Persönlichkeitsbewertung",
  language = "de",
  demographics = c("Alter", "Geschlecht")
)

# Spanish interface  
config_es <- create_study_config(
  name = "Evaluación de Personalidad",
  language = "es"
)

# French interface
config_fr <- create_study_config(
  name = "Évaluation de la Personnalité", 
  language = "fr"
)
```

## Themes and Appearance

Customize the appearance of your test:

```{r}
# Professional theme
config_pro <- create_study_config(
  name = "Clinical Assessment",
  theme = "professional"
)

# Academic theme
config_academic <- create_study_config(
  name = "Research Study",
  theme = "academic"
)

# Dark theme
config_dark <- create_study_config(
  name = "Modern Assessment",
  theme = "dark"
)
```

## Results and Data Export

After participants complete the test, results are automatically saved:

```{r}
# Results are saved in multiple formats:
# - RDS files for R analysis
# - CSV files for Excel/SPSS
# - JSON files for web applications
# - PDF reports for participants

# Load and analyze results
results <- readRDS("study_results.rds")

# View participant data
head(results$participants)

# View item responses
head(results$responses)

# View ability estimates
head(results$abilities)
```

## Next Steps

- **Customizing Appearance**: Learn how to customize themes and branding in the "Customizing Appearance" vignette
- **Research Workflows**: Explore advanced features for research applications
- **Advanced Configuration**: Learn about complex study designs and deployment options

For more detailed examples and advanced features, see the other vignettes in this package.

## References

- Robitzsch, A., Kiefer, T., & Wu, M. (2020). *TAM: Test Analysis Modules*. R package version 3.5-19.
- Samejima, F. (1969). Estimation of latent ability using a response pattern of graded scores. *Psychometrika Monograph Supplement*, 34(4), 100-114.
- van der Linden, W. J., & Glas, C. A. (Eds.). (2010). *Elements of adaptive testing*. Springer.
